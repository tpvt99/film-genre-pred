{"cells":[{"cell_type":"markdown","source":["# Notebook 2: Baselines and Multi-Layer Perceptrons"],"metadata":{"id":"rpaHRkH1o9hO"}},{"cell_type":"markdown","source":["In this notebook we begin exploring basic classification approaches, and we apply our first deep learning model to this task. In addition, we create a elegant framework for running experiments easily, and define our experiment. \n","\n","In addition to this, we evaluate some non-DL baselines provided by [this paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3547887) and the supporting tutorial.\n","\n","Finally, we render some illustrations to help us visualize the training process.\n","\n","Highlights!\n","\n","1. We implement our deep learning experimentation framework from scratch, implementing many functioanlities explicitly.\n","\n","2. We render some fun illustrations such as our confusion matrix animation to understand our models. \n","\n","3. We deliver results in a zip structure that is useful for analysis\n","\n"],"metadata":{"id":"NjybPiS9pGz6"}},{"cell_type":"markdown","source":["Contents:\n","\n","1.   Data exploration \n","2.   Traditional ML baselines as in [this paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3547887)\n","3.   Custom deep learning experiment framework and MLP training\n","\n"],"metadata":{"id":"whv8GNvytmN4"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2196,"status":"ok","timestamp":1668596199251,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"},"user_tz":-480},"id":"aCoM_1CqZ057","outputId":"44fdead3-d19b-4986-b7e6-14a54c264cee"},"outputs":[{"output_type":"stream","name":"stdout","text":["3.4.0\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}],"source":["# Imports \n","!pip install gensim==4.2.0\n","!pip install matplotlib==3.4\n","\n","import gdown\n","import glob\n","import os\n","import re\n","import json\n","import math\n","import time\n","from datetime import datetime\n","import csv\n","import string\n","import matplotlib\n","from nltk import pos_tag\n","\n","import zipfile\n","import torch\n","from torch import nn\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","import gensim.downloader as api\n","from torchsummary import summary\n","from sklearn.metrics import accuracy_score\n","from nltk import word_tokenize, PorterStemmer\n","from nltk.corpus import stopwords\n","import nltk\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","\n","# Constants\n","FILMS_GENRE = [\n","    \"action\",\n","    \"adventure\",\n","    \"comedy\",\n","    \"drama\",\n","    \"horror\",\n","    \"romance\",\n","    \"scifi\", # science fiction\n","    \"fantasy\",\n","    \"historical\",\n","    \"crime\"\n","]\n","\n","TARGET_LKP = {\n","    \"action\": 0,\n","    \"adventure\": 1,\n","    \"comedy\": 2,\n","    \"drama\": 3,\n","    \"horror\": 4,\n","    \"romance\": 5,\n","    \"scifi\": 6,  # science fiction\n","    \"fantasy\": 7,\n","    \"historical\": 8,\n","    \"crime\": 9\n","}\n","\n","print(matplotlib.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":858},"executionInfo":{"elapsed":6225,"status":"ok","timestamp":1668596211979,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"},"user_tz":-480},"id":"nEPhOOabaM-f","outputId":"a891d558-b84c-490c-88ee-64830aeb4473"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=10fAkL5gOYjG0WcNIwZnZ1X9_n8pciT19\n","To: /content/data_full3.zip\n","100% 5.15M/5.15M [00:00<00:00, 17.4MB/s]\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data/action/action_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data/action/action_films.csv...\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data/adventure/adventure_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data/adventure/adventure_films.csv...\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data/comedy/comedy_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data/comedy/comedy_films.csv...\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data/drama/drama_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data/drama/drama_films.csv...\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data/horror/horror_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data/horror/horror_films.csv...\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data/romance/romance_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data/romance/romance_films.csv...\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data/scifi/scifi_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data/scifi/scifi_films.csv...\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data/fantasy/fantasy_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data/fantasy/fantasy_films.csv...\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data/historical/historical_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data/historical/historical_films.csv...\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data/crime/crime_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data/crime/crime_films.csv...\n","Dataframe (df) ready to be used!\n"]},{"output_type":"execute_result","data":{"text/plain":["       genre                                               plot\n","0     action  frank vega is a decorated vietnam war veteran ...\n","1     action  journalist matt nashs dylan walsh investigatio...\n","2     action  in the midtolate 1960s three young men leave t...\n","3     action  po sing the youngest son of chinese triad boss...\n","4     action  clay santell audie murphy has his horse stolen...\n","...      ...                                                ...\n","2677   crime  a mexican newspaperman wages a oneman war agai...\n","2678   crime  larry crain peter cookson a medical student on...\n","2679   crime  a texas ranger samantha payne opens up a fifte...\n","2680   crime  billy dempsey is a well dressed bank robber wh...\n","2681   crime  in 1985 bronx new york where millie and wilson...\n","\n","[2682 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-4cc8fc29-5f95-4e4a-91e3-e90841102096\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>genre</th>\n","      <th>plot</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>action</td>\n","      <td>frank vega is a decorated vietnam war veteran ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>action</td>\n","      <td>journalist matt nashs dylan walsh investigatio...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>action</td>\n","      <td>in the midtolate 1960s three young men leave t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>action</td>\n","      <td>po sing the youngest son of chinese triad boss...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>action</td>\n","      <td>clay santell audie murphy has his horse stolen...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2677</th>\n","      <td>crime</td>\n","      <td>a mexican newspaperman wages a oneman war agai...</td>\n","    </tr>\n","    <tr>\n","      <th>2678</th>\n","      <td>crime</td>\n","      <td>larry crain peter cookson a medical student on...</td>\n","    </tr>\n","    <tr>\n","      <th>2679</th>\n","      <td>crime</td>\n","      <td>a texas ranger samantha payne opens up a fifte...</td>\n","    </tr>\n","    <tr>\n","      <th>2680</th>\n","      <td>crime</td>\n","      <td>billy dempsey is a well dressed bank robber wh...</td>\n","    </tr>\n","    <tr>\n","      <th>2681</th>\n","      <td>crime</td>\n","      <td>in 1985 bronx new york where millie and wilson...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2682 rows Ã— 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cc8fc29-5f95-4e4a-91e3-e90841102096')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4cc8fc29-5f95-4e4a-91e3-e90841102096 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4cc8fc29-5f95-4e4a-91e3-e90841102096');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}],"source":["# Fetch the data\n","!gdown 10fAkL5gOYjG0WcNIwZnZ1X9_n8pciT19\n","os.makedirs(\"/content/data/\", exist_ok=True)\n","!cp /content/data_full3.zip /content/data/\n","path = \"/content/data/data_full3.zip\"\n","\n","initial_df = pd.DataFrame()\n","with zipfile.ZipFile(path) as z:\n","  for name in z.namelist():\n","    if name.endswith(\".csv\"):\n","      print(f'Loading data from {name}...')\n","      x = pd.read_csv(z.open(name))\n","      print(f'Loading completed from {name}...')\n","      initial_df = pd.concat([initial_df,x[['genre','plot']]],axis=0,ignore_index=True)\n","  print(\"Dataframe (df) ready to be used!\")\n","\n","initial_df"]},{"cell_type":"markdown","source":["# Data Exploration and Baselines\n","\n","---\n","\n"],"metadata":{"id":"7twjiOycOMeF"}},{"cell_type":"markdown","source":["We first look for some common sources of error in the dataset, before we begin using it. The three most common erorrs are:\n","\n","1.   Plot is null \n","2.   Plot is empty\n","3.   Extraction of the plot caused error\n","\n","Since this dataset is created by scraping through wikipedia, it can result in a noisy dataset, where the rows might be incomplete. We look for these errors first, and then begin by looking at the distribution of the datset. "],"metadata":{"id":"hkQDBPJwQ4IW"}},{"cell_type":"code","source":["# 2(iii) - 1: Page with Section on Plot but contains no text, thus null or blank\n","plot_null_df = initial_df.loc[(initial_df['plot']==\"\") | (initial_df['plot'].isnull()) ]\n","plot_null_df['plot'] = \"Null\" #for plotting the null values\n","\n","# 2(iii) - 2:Page with no Section on Plot\n","no_section_plot_df = initial_df[initial_df['plot'] == \"Page with no Section on Plot\"]\n","\n","# 2(iii) - 3: Error (Unable to extract)\n","error_plot_df = initial_df[initial_df['plot'] == \"error\"]\n","\n","# 2(iii): removal of rows mentioned above to form final dataset that is useable\n","df = initial_df.copy()\n","df = df[~df['plot'].isnull()]\n","df = df[df['plot'] != \"\"]\n","df = df[df['plot'] != \"Page with no Section on Plot\"]\n","df = df[df['plot'] != \"error\"]\n","df.reset_index(drop=True,inplace=True)\n","\n","#Commence plotting\n","plt.figure(figsize = (30,15))\n","# 1st visual\n","if plot_null_df.size > 0:\n","  plt.subplot(2,2,1)\n","  plt.title(\"Number of films by Genre with Null/Blank plot\")\n","\n","  ax = sns.countplot(x = 'genre', data = plot_null_df) #order=plot_null_df['genre'].value_counts(ascending=False).index\n","  abs_values = plot_null_df['genre'].value_counts(sort=False).values\n","  ax.bar_label(container=ax.containers[0], labels=abs_values)\n","else:\n","  print (\"There are no films with null plots\")\n","\n","# 2nd visual\n","if no_section_plot_df.size > 0:\n","  plt.subplot(2,2,2)\n","  plt.title(\"Number of Films by Genre without section on plot\")\n","\n","  ax = sns.countplot(x = 'genre', data = no_section_plot_df) #order=no_section_plot_df['genre'].value_counts(ascending=False).index\n","  abs_values = no_section_plot_df['genre'].value_counts(sort=False).values\n","  ax.bar_label(container=ax.containers[0], labels=abs_values)\n","else:\n","  print(\"There are no films with missing plot sections in this dataset\")\n","\n","# 3rd visual -- There are no errors in this dataset, for other random_state, errors do exist.\n","\n","if error_plot_df.size > 0:\n","  plt.subplot(2,2,3)\n","  plt.title(\"Number of Films by Genre with error\")\n","\n","  ax = sns.countplot(x = 'genre', data = error_plot_df,order=error_plot_df['genre'].value_counts(ascending=False).index)\n","  abs_values = error_plot_df['genre'].value_counts(ascending=False).values\n","  ax.bar_label(container=ax.containers[0], labels=abs_values)\n","else: \n","  print (\"There are no films where extraction of the plot caused an error\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"FcgdAlewOkTu","executionInfo":{"status":"ok","timestamp":1668596217179,"user_tz":-480,"elapsed":400,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"e27e04ea-085b-414f-89f8-622c00eef283"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are no films with null plots\n","There are no films with missing plot sections in this dataset\n","There are no films where extraction of the plot caused an error\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2160x1080 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Shown below is the distribution of the dataset in each class. \n","\n","Observation: The sizes of the different classes are not balanced, and there are some classes like romance and fantasy that have far fewer data points. This is skewness in the data towards certain classes."],"metadata":{"id":"BVSO7EpOTR_C"}},{"cell_type":"code","source":["plt.figure(figsize = (10,5))\n","plt.title(\"Number of Films by Genre for final dataset\")\n","\n","ax = sns.countplot(x = 'genre', data = df,order=df['genre'].value_counts(ascending=False).index)\n","abs_values = df['genre'].value_counts(ascending=False).values\n","ax.bar_label(container=ax.containers[0], labels=abs_values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":524},"id":"TSGNGZopSxv1","executionInfo":{"status":"ok","timestamp":1668596224740,"user_tz":-480,"elapsed":1805,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"3cdbf48b-7c57-40f9-9993-2d1ee72b0df2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Text(0, 0, '342'),\n"," Text(0, 0, '311'),\n"," Text(0, 0, '299'),\n"," Text(0, 0, '286'),\n"," Text(0, 0, '279'),\n"," Text(0, 0, '276'),\n"," Text(0, 0, '271'),\n"," Text(0, 0, '249'),\n"," Text(0, 0, '209'),\n"," Text(0, 0, '160')]"]},"metadata":{},"execution_count":4},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Let us now do a few quick checks on the dataset to understand how it looks "],"metadata":{"id":"xGQurZH4TUS3"}},{"cell_type":"code","source":["df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0PFR14hSpvF","executionInfo":{"status":"ok","timestamp":1668596236913,"user_tz":-480,"elapsed":304,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"61539964-afd9-49ea-88b2-5de8cf572637"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['genre', 'plot'], dtype='object')"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"yaFWYzFNSeQ5","executionInfo":{"status":"ok","timestamp":1668596237632,"user_tz":-480,"elapsed":3,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"e3490810-2d36-4597-81fa-980e6553e594"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    genre                                               plot\n","0  action  frank vega is a decorated vietnam war veteran ...\n","1  action  journalist matt nashs dylan walsh investigatio...\n","2  action  in the midtolate 1960s three young men leave t...\n","3  action  po sing the youngest son of chinese triad boss...\n","4  action  clay santell audie murphy has his horse stolen..."],"text/html":["\n","  <div id=\"df-848c1e4d-46d4-4436-8402-abaf8ea9f7c6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>genre</th>\n","      <th>plot</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>action</td>\n","      <td>frank vega is a decorated vietnam war veteran ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>action</td>\n","      <td>journalist matt nashs dylan walsh investigatio...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>action</td>\n","      <td>in the midtolate 1960s three young men leave t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>action</td>\n","      <td>po sing the youngest son of chinese triad boss...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>action</td>\n","      <td>clay santell audie murphy has his horse stolen...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-848c1e4d-46d4-4436-8402-abaf8ea9f7c6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-848c1e4d-46d4-4436-8402-abaf8ea9f7c6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-848c1e4d-46d4-4436-8402-abaf8ea9f7c6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Let us explore the length of the plots in each genre and observe the number of stopwords in each section. This will help us understand if the data we have collected for each genre is inherently different. If basic linguistic characteristics such as the length of the plots are different, we could find that the representations we use (later) might not work the same way for all."],"metadata":{"id":"fNtqbuEWTjqH"}},{"cell_type":"code","source":["def stop_and_total_words_and_proportion_counter(dataframe_text_col):\n","    '''\n","    params: dataframe column / np array / list\n","    returns: (1) a list of elements for counts on # of stopwords in a sentence\n","             (2) a list of elements for counts on # of words in a sentence\n","             (3) a list of elements for (1)/(2) of each sentence\n","    '''\n","    total_time_taken = 0\n","    count_list_sw = []\n","    count_list_total = []\n","    proportion_of_stopwords = []\n","    count_sentence = 0\n","    stop_words = nltk.corpus.stopwords.words('english')\n","    for sentence in dataframe_text_col:\n","        start_time = time.time()\n","        tokenized = word_tokenize(sentence)\n","        # print(tokenized)\n","        count_stop_words = 0\n","        count_total_words = 0\n","        for word in tokenized:\n","            count_total_words +=1\n","            # print(F'Total word: {word} | {count_total_words}')\n","            if word in stop_words:\n","                count_stop_words +=1\n","                # print(f'Stop word: {word} | {count_stop_words}')\n","            else:\n","                count_stop_words = count_stop_words\n","        time_taken_per_sentence = time.time() - start_time\n","        total_time_taken += time_taken_per_sentence\n","        count_list_sw.append(count_stop_words)\n","        count_list_total.append(count_total_words)\n","        proportion_of_stopwords.append(count_stop_words/count_total_words)\n","        count_sentence +=1\n","        if count_sentence % 10000 == 0:\n","            print(f'#SENTENCE READ: {count_sentence} | time taken per sentence: {time_taken_per_sentence:.2f} second(s) | overall time taken: {total_time_taken/60:.2f} minute(s)')\n","    return count_list_sw , count_list_total , proportion_of_stopwords\n","\n","\n","# Computing stopwords count, plot length, and proportion of stopwords to plot length for each plot\n","df['stopwords_count'], df['word_count'], df['proportion_of_stopwords_to_wordcount'] = stop_and_total_words_and_proportion_counter(df['plot'])\n","df['proportion_of_stopwords_to_wordcount'] = df['proportion_of_stopwords_to_wordcount'].map('{:,.3f}'.format)\n","df['proportion_of_stopwords_to_wordcount'] = df[\"proportion_of_stopwords_to_wordcount\"].apply(lambda x: float(x))\n","\n","# 1st visual: distribution of genre by plot_length\n","plt.figure(figsize = (15,5))\n","plt.subplot(1,2,1)\n","plt.title('Box plot analysis of Genre by word count')\n","sns.boxplot(x = 'word_count', y='genre', data=df)\n","\n","# 2nd visual: distribution of genre by stopwords_count\n","plt.subplot(1,2,2)\n","plt.title('Box plot analysis of Genre by stopwords count')\n","sns.boxplot(x = 'stopwords_count', y='genre', data=df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"g-DLUUquTemN","executionInfo":{"status":"ok","timestamp":1668596250975,"user_tz":-480,"elapsed":11464,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"bdb33421-66fb-45c0-9fe3-da979dc96a59"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<AxesSubplot:title={'center':'Box plot analysis of Genre by stopwords count'}, xlabel='stopwords_count', ylabel='genre'>"]},"metadata":{},"execution_count":7},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x360 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["We see some variation in the mean word_count shown below. Here we are looking at the average statistics per genre, and we are seeing that some genre's like \"fantasy\" and \"scifi\" have much longer plot summaries. \n","\n","Since wikipedia's data is crowdsourced, it is possible that human factors involving the contributors to the two categories impact the difference, rather than any statistically significant information about then genre. To get a better picture we look at the full statistics of the word_count column.\n","\n","As expected from crowd sourced data, we observe:\n","\n","1.  High standard deviation in the word count, which means that we see high variance around the mean. This means that our dataset is not consistent in the text format. However, data quality is not in our control, and it comes at the compromise of data volume.\n","\n","2.  The 50th percentile (a more resillient measure than mean when subject to outliers), is to the left of the mean, indicating that some very long plots have pulled the mean to the right."],"metadata":{"id":"59KElzoVVW_T"}},{"cell_type":"code","source":["# We calculate the mean of world_count for each genre\n","df.groupby('genre').mean().reset_index()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"6tt-zKhIVGhR","executionInfo":{"status":"ok","timestamp":1668596553144,"user_tz":-480,"elapsed":341,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"28aac0bc-6530-4626-b963-39e1947b08d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        genre  stopwords_count  word_count  \\\n","0      action       147.772575  343.775920   \n","1   adventure       129.202797  294.482517   \n","2      comedy       120.148551  269.739130   \n","3       crime       124.280443  281.099631   \n","4       drama       119.562724  268.333333   \n","5     fantasy       204.229665  457.889952   \n","6  historical       172.594378  398.417671   \n","7      horror       165.695906  367.871345   \n","8     romance       136.906250  303.525000   \n","9       scifi       175.996785  401.456592   \n","\n","   proportion_of_stopwords_to_wordcount  \n","0                              0.424579  \n","1                              0.429490  \n","2                              0.435217  \n","3                              0.431417  \n","4                              0.436312  \n","5                              0.442215  \n","6                              0.428506  \n","7                              0.446310  \n","8                              0.439687  \n","9                              0.431585  "],"text/html":["\n","  <div id=\"df-6282dd7e-5c66-49f5-a1f7-6dbb0f6468f4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>genre</th>\n","      <th>stopwords_count</th>\n","      <th>word_count</th>\n","      <th>proportion_of_stopwords_to_wordcount</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>action</td>\n","      <td>147.772575</td>\n","      <td>343.775920</td>\n","      <td>0.424579</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>adventure</td>\n","      <td>129.202797</td>\n","      <td>294.482517</td>\n","      <td>0.429490</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>comedy</td>\n","      <td>120.148551</td>\n","      <td>269.739130</td>\n","      <td>0.435217</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>crime</td>\n","      <td>124.280443</td>\n","      <td>281.099631</td>\n","      <td>0.431417</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>drama</td>\n","      <td>119.562724</td>\n","      <td>268.333333</td>\n","      <td>0.436312</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>fantasy</td>\n","      <td>204.229665</td>\n","      <td>457.889952</td>\n","      <td>0.442215</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>historical</td>\n","      <td>172.594378</td>\n","      <td>398.417671</td>\n","      <td>0.428506</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>horror</td>\n","      <td>165.695906</td>\n","      <td>367.871345</td>\n","      <td>0.446310</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>romance</td>\n","      <td>136.906250</td>\n","      <td>303.525000</td>\n","      <td>0.439687</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>scifi</td>\n","      <td>175.996785</td>\n","      <td>401.456592</td>\n","      <td>0.431585</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6282dd7e-5c66-49f5-a1f7-6dbb0f6468f4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6282dd7e-5c66-49f5-a1f7-6dbb0f6468f4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6282dd7e-5c66-49f5-a1f7-6dbb0f6468f4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# summary statistics of word counts\n","print(df['word_count'].describe())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vCubZYuVy3G","executionInfo":{"status":"ok","timestamp":1668596554870,"user_tz":-480,"elapsed":2,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"27e10561-a07b-46d3-81d2-7e709f70bfe4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["count    2682.000000\n","mean      338.044743\n","std       281.847043\n","min        10.000000\n","25%        87.000000\n","50%       256.000000\n","75%       567.750000\n","max      2321.000000\n","Name: word_count, dtype: float64\n"]}]},{"cell_type":"markdown","source":["Looking further at the distribution of the word count, we have the following histogram.\n","\n","A quick look tells us that:\n","\n","1. Adventure is skewed towards short plots\n","2. Scifi is skewed towards long plots (>500 words)\n","3. Other genres seem to follow a closer distribution."],"metadata":{"id":"2ym8t6XyXIe1"}},{"cell_type":"code","source":["# Distribution of the word count per genre\n","from matplotlib import pyplot\n","\n","for genre in df['genre'].unique().tolist():\n","  x = df[df['genre']==genre].word_count\n","\n","  pyplot.hist(x, bins=50, alpha=0.5, label=genre)\n","  \n","pyplot.legend(loc='upper right')\n","pyplot.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"x68It3BtXIEp","executionInfo":{"status":"ok","timestamp":1668596558776,"user_tz":-480,"elapsed":1847,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"3556e268-3f1c-4ab8-ec82-3dfe31681457"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# We drop the analytics columns before proceeding to the model phase\n","df.drop(columns=['stopwords_count', 'word_count', 'proportion_of_stopwords_to_wordcount'],axis=1,inplace=True)\n","df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_oLFHCJXtg_","executionInfo":{"status":"ok","timestamp":1668555781383,"user_tz":-480,"elapsed":322,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"3915ab10-9fe4-4412-83b2-fac7732ae5fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['genre', 'plot'], dtype='object')"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["# Traditional ML\n","\n","Reference for this section: [Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3547887)\n","\n","As this is the baseline for our project, we **use an existing implementation from this paper for this section** provided by this paper and accompanying tutorial, and we use this for this section on Traditional ML. The code-cells are hidden by default as they are not the focus."],"metadata":{"id":"hxIs__LwlAZv"}},{"cell_type":"markdown","source":["  ### TF-IDF based vectorization"],"metadata":{"id":"DV3hOLKRmtc8"}},{"cell_type":"code","source":["# Later in the last section we implement our TF-IDF, but we start with the \n","# implemented one.\n","# We convert the text plot into a vector using the TF-IDF scores\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","tfidf = TfidfVectorizer(strip_accents=None,\n","                        lowercase=False,\n","                        preprocessor=None)\n","\n","from sklearn.utils import shuffle\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import GridSearchCV\n","\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import auc \n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","\n","# Shuffle \n","np.random.seed(0)\n","df = df.reindex(np.random.permutation(df.index))\n","stopwords = list(set(stopwords.words('english')))\n","\n","X = df['plot']\n","Y = df['genre']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"],"metadata":{"id":"omD3eNO6k_m2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GridSearch()\n","###########################################\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV\n","\n","tfidf = TfidfVectorizer(strip_accents=None,\n","                        lowercase=False,\n","                        preprocessor=None)\n","\n","param_grid = {'vect__ngram_range': [(1, 1)],          \n","              'vect__stop_words': [stopwords, None],\n","              'vect__max_df': [0.3, 0.5],\n","              'vect__max_features': [None, 1000],                                          \n","              'clf__n_estimators': [100, 200],\n","              'clf__learning_rate': [0.001, 0.01]\n","              }\n","\n","tree = DecisionTreeClassifier(max_depth=5)\n","\n","lr_tfidf = Pipeline([('vect', tfidf),\n","                     ('clf', AdaBoostClassifier(base_estimator=tree))]\n","                    )\n","\n","# on cross-validation parameters\n","cv = StratifiedKFold(n_splits=3, \n","                     shuffle=False\n","                     )\n","\n","gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n","                           scoring='accuracy',\n","                           cv=cv, \n","                           n_jobs=1, verbose=2)\n","\n","gs_lr_tfidf.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65IqCFy8maJs","executionInfo":{"status":"ok","timestamp":1668598609826,"user_tz":-480,"elapsed":1915516,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"80dafaa1-6012-44fb-8e41-5e2231f38daf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 32 candidates, totalling 96 fits\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  21.1s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  18.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  18.0s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  20.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  19.4s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  18.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   6.9s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   6.9s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   6.9s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   8.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   7.8s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   7.6s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  17.3s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  18.0s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  19.0s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  20.8s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  21.0s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  21.0s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   7.1s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   8.1s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   7.0s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   8.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   8.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   8.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  41.5s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  35.8s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  34.8s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  39.2s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  40.4s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  42.4s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  14.2s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  14.2s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  13.8s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  15.0s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  15.2s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  15.1s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  38.2s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  37.9s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  35.6s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  38.9s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  41.4s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  41.4s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  13.3s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  13.5s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  13.3s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  16.5s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  16.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  16.8s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  17.9s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  17.7s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  17.3s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  18.1s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  17.8s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  18.2s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   6.9s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   6.8s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   6.7s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   7.5s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   7.6s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   7.6s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  16.9s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  17.3s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  17.4s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  19.2s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  19.7s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  19.7s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   6.9s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   7.1s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=   6.9s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   8.6s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   8.5s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=   8.5s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  33.1s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  32.6s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  33.2s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  34.3s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  34.5s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  35.7s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  12.8s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  12.8s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  12.9s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  14.4s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  14.3s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.3, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  14.5s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  33.2s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  33.1s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  33.8s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  37.1s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  37.6s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=None, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  37.3s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  13.2s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  13.1s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']; total time=  13.1s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  16.4s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  16.1s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__max_df=0.5, vect__max_features=1000, vect__ngram_range=(1, 1), vect__stop_words=None; total time=  16.3s\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n","             estimator=Pipeline(steps=[('vect',\n","                                        TfidfVectorizer(lowercase=False)),\n","                                       ('clf',\n","                                        AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5)))]),\n","             n_jobs=1,\n","             param_grid={'clf__learning_rate': [0.001, 0.01],\n","                         'clf__n_estimators': [100, 200],\n","                         'vect__max_df': [0.3, 0.5],\n","                         'vect__max_features': [None, 1000],\n","                         'vect__ngram_range': [(1, 1)],\n","                         'vect__stop_words': [['if', 'doing', 'from', \"haven't\",\n","                                               'off', 'only', \"weren't\", 'of',\n","                                               'then', \"you're\", 'weren',\n","                                               'through', 'hasn', 'theirs',\n","                                               'having', \"don't\", 'not', 'down',\n","                                               'all', 'me', 'once', 'those',\n","                                               'how', 'more', 'wouldn',\n","                                               \"you've\", \"wasn't\", 'she', 'to',\n","                                               'we', ...],\n","                                              None]},\n","             scoring='accuracy', verbose=2)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# best estimator - test performance\n","###########################################\n","\n","clf_b = gs_lr_tfidf.best_estimator_\n","y_pred_proba = clf_b.predict_proba(X_test)\n","y_pred = clf_b.predict(X_test)\n","\n","# Accuracy on test data\n","acc = accuracy_score(y_test, y_pred)\n","\n","# collecting results\n","###########################################\n","\n","\n","print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n","print('Test Accuracy: %.3f' % acc)"],"metadata":{"id":"JY8kHQjWmkvI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668598610464,"user_tz":-480,"elapsed":640,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"d06d6835-bc7a-4c91-9375-3a62a71d8e8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best parameter set: {'clf__learning_rate': 0.01, 'clf__n_estimators': 200, 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__ngram_range': (1, 1), 'vect__stop_words': ['if', 'doing', 'from', \"haven't\", 'off', 'only', \"weren't\", 'of', 'then', \"you're\", 'weren', 'through', 'hasn', 'theirs', 'having', \"don't\", 'not', 'down', 'all', 'me', 'once', 'those', 'how', 'more', 'wouldn', \"you've\", \"wasn't\", 'she', 'to', 'we', 'which', 're', 'same', 'this', 'by', 'when', \"needn't\", \"hasn't\", 'as', 'been', 'hadn', 'own', 'y', 'mustn', \"couldn't\", 'too', 's', 'so', 'their', 'did', \"it's\", 'the', \"mustn't\", \"aren't\", 'both', 'can', 'hers', 'haven', 'ain', 'now', 'they', 'who', 'nor', 'just', 'should', 'don', \"mightn't\", 'our', 'out', \"didn't\", 'was', 'didn', 'are', 'o', 'doesn', \"you'd\", 'its', 'with', 'an', \"doesn't\", 'yourselves', 'his', 'against', 'why', 'again', 'under', 'mightn', 'up', 'does', 'about', 'were', 'into', 'he', 'll', 'is', 'be', 'wasn', \"wouldn't\", 'it', 'what', 'and', 'my', 'no', 'here', 'has', 've', 'above', 'isn', 'a', 'ma', 'shouldn', \"hadn't\", 'or', 'than', 'at', 'your', 'each', 'whom', \"won't\", 'aren', 'other', 'such', \"shouldn't\", 'being', 'do', \"shan't\", 'her', 'few', \"isn't\", \"should've\", 'won', 'for', 'yourself', 'these', 'between', 'herself', 'on', 'below', 'them', 'that', 'yours', 'before', 'most', 'am', 'until', 'some', 'shan', 'd', 'will', 'have', 'in', \"you'll\", 'm', 'because', 't', 'during', 'but', 'him', 'themselves', 'ours', 'had', 'over', 'i', 'myself', \"she's\", 'needn', 'while', 'himself', 'itself', 'couldn', 'you', \"that'll\", 'very', 'after', 'any', 'ourselves', 'there', 'where', 'further']} \n","Test Accuracy: 0.348\n"]}]},{"cell_type":"markdown","source":["### Part of speech based models\n"],"metadata":{"id":"r7RgadLCm7x2"}},{"cell_type":"code","source":["from sklearn.utils import shuffle\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import GridSearchCV\n","\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import auc \n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","\n","def pos_tags(text):\n","    text_processed = word_tokenize(text)\n","    return \"-\".join( tag for (word, tag) in nltk.pos_tag(text_processed))\n","\n","pos_tags(df.loc[0, 'plot'])\n","\n","np.random.seed(0)\n","df = df.reindex(np.random.permutation(df.index))\n","df['text_pos']=df.apply(lambda x: pos_tags(x['plot']), axis=1)\n","X = df['text_pos']\n","Y = df['genre']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","# GridSearch()\n","###########################################\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV\n","\n","tfidf = TfidfVectorizer(strip_accents=None,\n","                        lowercase=False,\n","                        preprocessor=None)\n","\n","param_grid = {'vect__ngram_range': [(1, 1)],               # we consider only 1-gram POS (for 2-grams: (1,2))\n","              'clf__n_estimators': [100, 200, 400],\n","              'clf__learning_rate': [0.001, 0.01, 1.0]}\n","\n","tree = DecisionTreeClassifier(max_depth=5)\n","\n","lr_tfidf = Pipeline([('vect', tfidf),\n","                     ('clf', AdaBoostClassifier(base_estimator=tree))]\n","                    )\n","\n","# on cross-validation parameters\n","cv = StratifiedKFold(n_splits=3, \n","                     shuffle=False\n","                     )\n","\n","gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n","                           scoring='accuracy',\n","                           cv=cv, \n","                           n_jobs=1, verbose=2)\n","\n","gs_lr_tfidf.fit(X_train, y_train)"],"metadata":{"id":"Q3dVyoT9m6pt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668599349162,"user_tz":-480,"elapsed":247154,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"b52c0938-7957-4912-d094-6a8f013a0182"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 9 candidates, totalling 27 fits\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__ngram_range=(1, 1); total time=   4.0s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__ngram_range=(1, 1); total time=   3.1s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=100, vect__ngram_range=(1, 1); total time=   3.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__ngram_range=(1, 1); total time=   6.6s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__ngram_range=(1, 1); total time=   5.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=200, vect__ngram_range=(1, 1); total time=   5.7s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=400, vect__ngram_range=(1, 1); total time=  10.9s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=400, vect__ngram_range=(1, 1); total time=  11.0s\n","[CV] END clf__learning_rate=0.001, clf__n_estimators=400, vect__ngram_range=(1, 1); total time=  10.9s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__ngram_range=(1, 1); total time=   3.0s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__ngram_range=(1, 1); total time=   3.0s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=100, vect__ngram_range=(1, 1); total time=   3.0s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__ngram_range=(1, 1); total time=   5.6s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__ngram_range=(1, 1); total time=   5.6s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=200, vect__ngram_range=(1, 1); total time=   5.6s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=400, vect__ngram_range=(1, 1); total time=  11.1s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=400, vect__ngram_range=(1, 1); total time=  12.4s\n","[CV] END clf__learning_rate=0.01, clf__n_estimators=400, vect__ngram_range=(1, 1); total time=  10.9s\n","[CV] END clf__learning_rate=1.0, clf__n_estimators=100, vect__ngram_range=(1, 1); total time=   2.9s\n","[CV] END clf__learning_rate=1.0, clf__n_estimators=100, vect__ngram_range=(1, 1); total time=   2.9s\n","[CV] END clf__learning_rate=1.0, clf__n_estimators=100, vect__ngram_range=(1, 1); total time=   2.9s\n","[CV] END clf__learning_rate=1.0, clf__n_estimators=200, vect__ngram_range=(1, 1); total time=   5.4s\n","[CV] END clf__learning_rate=1.0, clf__n_estimators=200, vect__ngram_range=(1, 1); total time=   5.5s\n","[CV] END clf__learning_rate=1.0, clf__n_estimators=200, vect__ngram_range=(1, 1); total time=   5.4s\n","[CV] END clf__learning_rate=1.0, clf__n_estimators=400, vect__ngram_range=(1, 1); total time=  10.5s\n","[CV] END clf__learning_rate=1.0, clf__n_estimators=400, vect__ngram_range=(1, 1); total time=  10.5s\n","[CV] END clf__learning_rate=1.0, clf__n_estimators=400, vect__ngram_range=(1, 1); total time=  10.5s\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n","             estimator=Pipeline(steps=[('vect',\n","                                        TfidfVectorizer(lowercase=False)),\n","                                       ('clf',\n","                                        AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5)))]),\n","             n_jobs=1,\n","             param_grid={'clf__learning_rate': [0.001, 0.01, 1.0],\n","                         'clf__n_estimators': [100, 200, 400],\n","                         'vect__ngram_range': [(1, 1)]},\n","             scoring='accuracy', verbose=2)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# best estimator - test performance\n","###########################################\n","\n","clf_b = gs_lr_tfidf.best_estimator_\n","y_pred_proba = clf_b.predict_proba(X_test)\n","y_pred = clf_b.predict(X_test)\n","\n","# Accuracy on test data\n","acc = accuracy_score(y_test, y_pred)\n","\n","# collecting results\n","###########################################\n","\n","\n","print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n","print('Test Accuracy: %.3f' % acc)"],"metadata":{"id":"Dq50cUBsnbgv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668599579186,"user_tz":-480,"elapsed":883,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"16fea429-a9d0-4623-8ff1-1ccdea1dd961"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best parameter set: {'clf__learning_rate': 1.0, 'clf__n_estimators': 400, 'vect__ngram_range': (1, 1)} \n","Test Accuracy: 0.209\n"]}]},{"cell_type":"markdown","source":["### Word embeddings based models\n"],"metadata":{"id":"OugxDX2LnB09"}},{"cell_type":"code","source":["!python -m spacy download en_core_web_md\n","\n","import spacy\n","nlp = spacy.load('en_core_web_md') \n","\n","# Shuffle\n","np.random.seed(0)\n","df = df.reindex(np.random.permutation(df.index))\n","\n","emb = np.vstack(df['plot'].apply(lambda x: nlp(x).vector))\n","X = emb\n","Y = df['genre']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {'clf__n_estimators': [100, 250, 400],\n","              'clf__learning_rate': [0.001, 0.01]}\n","\n","tree = DecisionTreeClassifier(max_depth=5)\n","\n","pipe = Pipeline([('clf', AdaBoostClassifier(base_estimator=tree))])\n","\n","# on cross-validation parameters\n","cv = StratifiedKFold(n_splits=3, \n","                     shuffle=False\n","                     )\n","\n","gs_lr_tfidf = GridSearchCV(pipe, param_grid,\n","                           scoring='accuracy',\n","                           cv=cv, \n","                           n_jobs=1, verbose=2)                       \n","# running the grid\n","###########################################\n","\n","gs_lr_tfidf.fit(X_train, y_train)"],"metadata":{"id":"DGtIaCjgnBNx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668601155174,"user_tz":-480,"elapsed":1566902,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"a24dc3ed-c4e1-483d-f7a6-a86d66321621"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-11-16 11:53:12.411624: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-md==3.4.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.1/en_core_web_md-3.4.1-py3-none-any.whl (42.8 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.8 MB 283 kB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-md==3.4.1) (3.4.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (21.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.10.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.11.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.21.6)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.1.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.10)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.23.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.8)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.4.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.7)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.5)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (57.4.0)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.4.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.6.2)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.10.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.4)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.0.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.1)\n","Installing collected packages: en-core-web-md\n","Successfully installed en-core-web-md-3.4.1\n","\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_md')\n","Fitting 3 folds for each of 6 candidates, totalling 18 fits\n","[CV] END ....clf__learning_rate=0.001, clf__n_estimators=100; total time=  26.3s\n","[CV] END ....clf__learning_rate=0.001, clf__n_estimators=100; total time=  28.5s\n","[CV] END ....clf__learning_rate=0.001, clf__n_estimators=100; total time=  29.9s\n","[CV] END ....clf__learning_rate=0.001, clf__n_estimators=250; total time= 1.1min\n","[CV] END ....clf__learning_rate=0.001, clf__n_estimators=250; total time= 1.1min\n","[CV] END ....clf__learning_rate=0.001, clf__n_estimators=250; total time= 1.1min\n","[CV] END ....clf__learning_rate=0.001, clf__n_estimators=400; total time= 1.7min\n","[CV] END ....clf__learning_rate=0.001, clf__n_estimators=400; total time= 1.7min\n","[CV] END ....clf__learning_rate=0.001, clf__n_estimators=400; total time= 1.7min\n","[CV] END .....clf__learning_rate=0.01, clf__n_estimators=100; total time=  26.2s\n","[CV] END .....clf__learning_rate=0.01, clf__n_estimators=100; total time=  26.2s\n","[CV] END .....clf__learning_rate=0.01, clf__n_estimators=100; total time=  26.1s\n","[CV] END .....clf__learning_rate=0.01, clf__n_estimators=250; total time= 1.5min\n","[CV] END .....clf__learning_rate=0.01, clf__n_estimators=250; total time= 1.2min\n","[CV] END .....clf__learning_rate=0.01, clf__n_estimators=250; total time= 1.2min\n","[CV] END .....clf__learning_rate=0.01, clf__n_estimators=400; total time= 1.8min\n","[CV] END .....clf__learning_rate=0.01, clf__n_estimators=400; total time= 1.8min\n","[CV] END .....clf__learning_rate=0.01, clf__n_estimators=400; total time= 1.7min\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n","             estimator=Pipeline(steps=[('clf',\n","                                        AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5)))]),\n","             n_jobs=1,\n","             param_grid={'clf__learning_rate': [0.001, 0.01],\n","                         'clf__n_estimators': [100, 250, 400]},\n","             scoring='accuracy', verbose=2)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# best estimator - test performance\n","###########################################\n","\n","clf_b = gs_lr_tfidf.best_estimator_\n","y_pred_proba = clf_b.predict_proba(X_test)\n","y_pred = clf_b.predict(X_test)\n","\n","\n","# Accuracy on test data\n","acc = accuracy_score(y_test, y_pred)\n","\n","# collecting results\n","###########################################\n","\n","\n","print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n","\n","print('Test Accuracy: %.3f' % acc)"],"metadata":{"id":"WtVRM0HBn0_a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668601208300,"user_tz":-480,"elapsed":859,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"65eaf0f3-f4ac-492e-a53e-28047faa949a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best parameter set: {'clf__learning_rate': 0.01, 'clf__n_estimators': 400} \n","Test Accuracy: 0.339\n"]}]},{"cell_type":"markdown","source":["# Deep Learning 1: Multi-Layer Perceptron (MLP)"],"metadata":{"id":"bTKP5vscX55m"}},{"cell_type":"markdown","source":["This section has functionality implemented from scratch!\n","\n","In this section we aim to achieve the following objectives: \n","\n","1. Explore word embeddings to transform text plots into vectors \n","2. Create a framework that is capable of running a large number of experiments with configurable parameters including both basic and complex configurations\n","\n","    - Epochs \n","    - Model architecture (types of layers, parameters to layers, etc.)\n","    - Learning rate\n","    - Down/up-sampling dataset\n","    - Model checkpointing \n","    - Word embedding dimension\n","    - Batch size\n","    - Source data\n","    - Sentence embedding strategy (simple mean / tf-idf weighted mean)\n","    - Text cleaning strategy\n","3. Run experiments with different parameters to identify the best parameter set.\n","4. Display analytics for the classification problem\n","\n","\n"],"metadata":{"id":"IzA_VN6RX_7-"}},{"cell_type":"markdown","source":["### Utility functions \n","\n","\n"],"metadata":{"id":"xwkhg6RVcGux"}},{"cell_type":"markdown","source":["Define common classes including a SentCleaner, which implements tokenization, lower casing, stop word removal, punctuation and escape removal. \n","\n","Pre-processing text is vital to Natural Languauge Processing (NLP) tasks. We perform the following pre-processing steps:\n","\n","1. Tokenization: Splitting a sentence into separate tokens which are words. These words are then processed further.\n","2. Lower casing: Lower case all the words to standardize them\n","3. Stop word removal: Most sentences contain a lot of common words from the language which are not significant to the meaning of the sentence, but required for gramatical correctness. \n","For example, articles like 'a' and 'the' are sometimes important to the meaning (e.g., \"the reason I study..\" vs \"a reason I study..\" imply a differnece in cardinality of the reasons), but in the vast majority of cases are used because articles are required to identify the noun being referred to. \n","While using with word embeddings in the averaging fashion, we remove stop words to make the dataset size more manageable.\n","\n"],"metadata":{"id":"XBHar7hacUiI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JXBemc6Sa6rs"},"outputs":[],"source":["from nltk.corpus import stopwords\n","# Define some utils classes and methods\n","\n","\"\"\"\n","Read configs from file for defining training\n","\"\"\"\n","def get_configs(config_file=\"config.json\"):\n","    with open(config_file, 'r') as fp:\n","        return json.load(fp)[\"configs\"]\n","\n","\"\"\"\n","Create default text cleaning config\n","\"\"\"\n","def get_default_sent_cleaner_conf():\n","    # Sentence cleaner conf\n","    sent_cleaner_conf = dict()\n","    sent_cleaner_conf['token'] = True\n","    sent_cleaner_conf['lower'] = True\n","    sent_cleaner_conf['encode'] = False\n","    sent_cleaner_conf['remove_stop'] = True\n","    sent_cleaner_conf['remove_punc'] = True\n","    sent_cleaner_conf['remove_esc'] = True\n","    sent_cleaner_conf['stem'] = False\n","\n","    return sent_cleaner_conf\n","\n","\"\"\"\n","Create default text cleaning config\n","\"\"\"\n","def get_default_sent_cleaner_conf_all_false():\n","    # Sentence cleaner conf\n","    sent_cleaner_conf = dict()\n","    sent_cleaner_conf['token'] = True\n","    sent_cleaner_conf['lower'] = False\n","    sent_cleaner_conf['encode'] = False\n","    sent_cleaner_conf['remove_stop'] = False\n","    sent_cleaner_conf['remove_punc'] = False\n","    sent_cleaner_conf['remove_esc'] = False\n","    sent_cleaner_conf['stem'] = False\n","\n","    return sent_cleaner_conf\n","\n","\"\"\"\n","Create default down-sampling config\n","\"\"\"\n","# Set up default conf\n","def get_default_down_sample_conf():\n","    # Down sample conf\n","    down_sample_conf = dict()\n","\n","    for genre in FILMS_GENRE:\n","        down_sample_conf[genre] = 0\n","\n","    return down_sample_conf\n","\n","\n","\"\"\"\n","Simple logger to write training outputs to \n","training log file\n","\"\"\"\n","class Logger:\n","    def __init__(self, output_dir, file_name, class_name):\n","        self.output_dir = output_dir\n","        self.file_name = file_name\n","        self.class_name = class_name\n","        self.fp = open(os.path.join(self.output_dir, file_name), \"a+\")\n","\n","    def log(self, to_log):\n","        now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n","        self.fp.write(f\"{now}: {to_log}\\n\")\n","        self.fp.flush()\n","\n","    def close(self):\n","        self.fp.close()\n","\n","\n","\"\"\"\n","Implement text cleaning in a simple cleaner class\n","\"\"\"\n","class SentCleaner:\n","    def __init__(self, sent, conf):\n","        self.sent = sent\n","        self.sent_tokenized = None\n","        self.conf = conf\n","\n","    def lower_case(self):\n","        if self.conf['lower']:\n","            self.sent = self.sent.lower()\n","        return self\n","\n","    def tokenize(self):\n","        if self.conf['token']:\n","            self.sent_tokenized = word_tokenize(self.sent)\n","        return self\n","\n","    def remove_stopwords(self, stop_words):\n","        if self.conf['remove_stop']:\n","            self.sent_tokenized = [word for word in self.sent_tokenized if word not in stop_words]\n","        return self\n","\n","    def remove_punct(self):\n","        if self.conf['remove_punc']:\n","            self.sent_tokenized = [word for word in self.sent_tokenized if re.search('[a-z]', word)]\n","        return self\n","\n","    def stem_words(self):\n","        if self.conf['stem']:\n","            stemmer = PorterStemmer()\n","            self.sent_tokenized = [stemmer.stem(word) for word in self.sent_tokenized]\n","        return self\n","\n","    def remove_escapes(self):\n","        if self.conf['remove_esc']:\n","            stripped = [word.replace('\\n', '') for word in self.sent_tokenized]\n","            self.sent_tokenized = [word for word in stripped if word != '']\n","        return self\n","\n","    def clean_sent(self):\n","        self.lower_case() \\\n","            .tokenize() \\\n","            .remove_punct() \\\n","            .remove_escapes() \\\n","            .stem_words() \\\n","            .remove_stopwords(stopwords.words('english'))\n","\n","        return self.sent_tokenized\n","\n","    def sent_v(self):\n","        return set(self.sent_tokenized)"]},{"cell_type":"markdown","source":["### Analytics"],"metadata":{"id":"bQc9AobMp7Hf"}},{"cell_type":"markdown","source":["We now define some basic analytics that are suitable to the classification problem, so that we can visualize the results once we have completed training. \n","\n","We set up the following plots and analytics to help us interpret the results:\n","\n","1. Confusion matrix: A confusion matrix helps visualise the propensity of the matrix to make every kind of classification error (\"confusion\"), and numerically shows in the matrix how many times each combination of error was made. The diagonal of the matrix contains the counts of the correct classification, and so what we expect to see is that as training proceeds, the values along the diagonal will grow.\n","\n","2. Loss plot: As a model is trained, we can check validation loss to understand how the model is generalising. This validation loss serves to let us know when we are over fitting to the training set. The test loss on the other hand is only seen after we have already picked the model to evaluate. We do not use this for model selection.\n","\n","3. Training and test statistics: Once we have split the dataset into the train, validation and test splits, we check to see the distribution of the training examples in each class. If any of those is heavily skewed in one direction, we could end up with a bad training run that does not generalise.\n","\n","4. Accuracy by class: As an extension of the confusion matrix, it is important for us to understand how well a model is doing in each class. It is very important to understand if it is classifying one class well, and another poorly, as it helps us guide future directions. Additionally, real world applications of models are often not possible in production unless there is a guarantee of a minimum performance on all classes. Hence, we look at this plot."],"metadata":{"id":"s8mCowlKd5G_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"InEl7Yn_cmEq"},"outputs":[],"source":["\"\"\"\n","Analytics and visualization for classification \n","problems\n","\"\"\"\n","class Analytics:\n","\n","    @staticmethod\n","    def confusion_matrix_analysis(Y_shuffled, Y_preds, model_name, epoch):\n","        Analytics.create_dirs_if_not_present(model_name)\n","        os.makedirs(f\"/content/outputs/{model_name}/confusion/\", exist_ok=True)\n","\n","        plt.clf()\n","        conf_mat = confusion_matrix(Y_shuffled, Y_preds)\n","\n","        # Normalise the array\n","        highest, lowest = np.max(conf_mat), np.min(conf_mat)\n","        value_range = highest - lowest\n","        conf_mat = conf_mat * (1.0 / value_range)\n","\n","        # Plot a heat map\n","        ax = sns.heatmap(conf_mat, linewidths=0.3, xticklabels=FILMS_GENRE, yticklabels=FILMS_GENRE)\n","        ax.set(title=f'Confusion at epoch: {epoch}')\n","        ax.figure.savefig(f\"/content/outputs/{model_name}/confusion/{epoch}.png\")\n","        plt.clf()\n","\n","    @staticmethod\n","    def create_animated_gifs(model_name):\n","        Analytics.create_dirs_if_not_present(model_name)\n","        sort_fn = lambda x: int(os.path.basename(x).split('/')[-1].split('.')[0])\n","        images = [Image.open(image) for image in sorted(glob.glob(f\"/content/outputs/{model_name}/confusion/*.png\"), key=sort_fn)]\n","        images[0].save(f\"/content/outputs/{model_name}/confusion/confusion.gif\", format=\"GIF\", append_images=images,\n","                       save_all=True, duration=len(images) / 2, loop=0)\n","\n","    @staticmethod\n","    def plot_loss(train_loss, val_loss, model_name):\n","        Analytics.create_dirs_if_not_present(model_name)\n","        plt.clf()\n","        epochs = np.arange(len(train_loss))\n","        plt.title(\"Training and Validation Loss\")\n","        plt.plot(epochs, train_loss, label=\"Train Loss\")\n","        plt.plot(epochs, val_loss, label=\"Validation Loss\")\n","        plt.xlabel(\"Epochs\")\n","        plt.ylabel(\"Loss\")\n","        plt.legend()\n","        plt.savefig(f\"outputs/{model_name}/loss.png\")\n","        plt.show()\n","        plt.clf()\n","\n","    @staticmethod\n","    def plot_acc(train_acc, val_acc, model_name):\n","        Analytics.create_dirs_if_not_present(model_name)\n","        plt.clf()\n","        epochs = np.arange(len(train_acc))\n","        plt.title(\"Training and Validation Acc\")\n","        plt.plot(epochs, train_acc, label=\"Train Acc\")\n","        plt.plot(epochs, val_acc, label=\"Validation Acc\")\n","        plt.xlabel(\"Epochs\")\n","        plt.ylabel(\"Accuracy\")\n","        plt.legend()\n","        plt.savefig(f\"outputs/{model_name}/loss.png\")\n","        plt.clf()\n","\n","    @staticmethod\n","    def show_train_val_test_stats(y_train, y_test, y_val, logger):\n","        ytr, yva, yte = np.array(y_train).astype(int), np.array(y_val).astype(int), np.array(y_test).astype(int)\n","        logger.log(\"Train statistics\")\n","        logger.log(np.unique(ytr, return_counts=True))\n","        logger.log(\"Validation statistics\")\n","        logger.log(np.unique(yva, return_counts=True))\n","        logger.log(\"Test statistics\")\n","        logger.log(np.unique(yte, return_counts=True))\n","\n","    @staticmethod\n","    def acc_by_class(Y_shuffled, Y_preds, model_name, epoch_num):\n","        os.makedirs(f\"/content/outputs/{model_name}/acc_by_class/\", exist_ok=True)\n","        Analytics.create_dirs_if_not_present(model_name)\n","        truth = np.array(Y_shuffled, dtype=int).reshape(-1)\n","        preds = np.array(Y_preds, dtype=int)\n","\n","        is_correct = (truth == preds).astype(int)\n","\n","        accuracies = []\n","\n","        for cat in range(len(FILMS_GENRE)):\n","            ind = np.where(truth == cat)\n","            total = len(ind[0]) + 1e-8\n","            correct = np.sum(is_correct[ind[0]])\n","\n","            accuracies.append(correct / total)\n","\n","        plt.clf()\n","        plt.title(f\"Accuracies by class - epoch-{epoch_num}\")\n","        plt.barh(FILMS_GENRE, accuracies)\n","        plt.xlabel(\"Classes\")\n","        plt.ylabel(\"Accuracy\")\n","        plt.savefig(f\"outputs/{model_name}/acc_by_class/{epoch_num}.png\")\n","        plt.clf()\n","        return accuracies\n","\n","    @staticmethod\n","    def plot_value_counts(df: pd.DataFrame, model_name, split):\n","        Analytics.create_dirs_if_not_present(model_name)\n","        plt.clf()\n","        plt.title(\"Frequencies by class\")\n","        plt.xlabel(\"Frequency\")\n","        plt.ylabel(\"Classes\")\n","        df['genre'].value_counts().plot(kind=\"barh\")\n","        plt.savefig(f\"/content/outputs/{model_name}/{split}_value_counts.png\", bbox_inches=\"tight\")\n","        plt.clf()\n","\n","    @staticmethod\n","    def create_dirs_if_not_present(model_name):\n","        os.makedirs(f\"/content/outputs/{model_name}\", exist_ok=True)\n","\n","    \"\"\"\n","    Sanity checks on visualization\n","    \"\"\"\n","    \n","    @staticmethod\n","    def test_confusion():\n","        a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","\n","        for i in range(10):\n","            b = [i] * 10\n","            Analytics.confusion_matrix_analysis(a, b, \"test\", i)\n","        Analytics.create_animated_gifs(\"test\")\n","\n","    @staticmethod\n","    def test_loss():\n","        a = [1] * 1000\n","        b = [2] * 1000\n","        Analytics.plot_loss(a, b, \"test\")\n","\n","    @staticmethod\n","    def test_value_counts():\n","        df = pd.DataFrame(columns=[\"genre\"], data=[[\"drama\"], [\"comedy\"], [\"comedy\"]])\n","        Analytics.plot_value_counts(df, \"test\")"]},{"cell_type":"markdown","source":["  ### Word embeddings and TF-IDF"],"metadata":{"id":"iUFNELxSqCE3"}},{"cell_type":"markdown","source":["We now implement TF-IDF from scratch. Term-frequency-Inverse Document Frequency is a fundamental and basic concept in NLP that basically serves help us vectorise a sentence by using statistics of the occurence of the words in each document vs the number of documents they occur in. The concept is summarised as:\n","\n","1. Good terms occur very often in a specific document, but they occur rarely across the dataset. This means this term will get a high score for containing valuable information about this document.\n","\n","2. Terms that occur in almost every document are not very valuable in understanding the difference between different documents. These terms will receive a low score even if their term frequency is high, as the inverse document frequency will pull it down to a small score. These are often the stop words.\n","\n"],"metadata":{"id":"Wi-D526MgKTm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4_37cRK4g-PI"},"outputs":[],"source":["\"\"\"\n","Implement basic tf-idf from scratch\n","\"\"\"\n","class TfIdfWeighter:\n","    def __init__(self, cleaned_plots):\n","        self.plots = cleaned_plots\n","        self.n = len(self.plots)\n","        l = max([len(pl) for pl in self.plots])\n","        self.tf_idf = np.zeros((self.n, l))\n","        self.vocab = set()\n","        self._set_vocab()\n","\n","    def calc_tf(self):\n","        for i, plot in enumerate(self.plots):\n","            _v = {}\n","            for word in plot:\n","                _v[word] = _v.get(word, 0) + 1\n","\n","            for j, word in enumerate(plot):\n","                self.tf_idf[i, j] = _v.get(word, 0)\n","\n","    def _set_vocab(self):\n","        for plot in self.plots:\n","            for word in plot:\n","                self.vocab.add(word)\n","\n","    def get_tf_idf(self):\n","        self.calc_tf()\n","        word_sets = [set(plot) for plot in self.plots]\n","        idf = {}\n","        for word in self.vocab:\n","            fn = lambda _w, _s: 1 if _w in _s else 0\n","            df = sum([fn(word, word_set) for word_set in word_sets])\n","            idf[word] = math.log(self.n / (1 + df))\n","\n","        for i, plot in enumerate(self.plots):\n","            for j, word in enumerate(plot):\n","                self.tf_idf[i, j] *= (idf.get(word, 0))\n","\n","        return self.tf_idf"]},{"cell_type":"markdown","source":["The use of word embeddings is more modern approach to NLP. We use pre-trained word vector representations to load vectors for each word that capture their meaning in some form. Word-embeddings are often trained on different corpora with different techniques, and the final models are provided to be used as pre-trained vectors.\n","\n","If we had a large enough dataset, we could also train our own embeddings. In our case, there are already pre-trained embeddings trained on the wikipedia dataset, so we use those embeddings out of the box. We explore:\n","\n","- glove (50, 100, 300 dimension)\n","- word2vec (300 dimension, trained on google news)\n","- fasttext\n","\n","This class helps load the word embeddings for use. The highlight of this class is that it can \n","\n","- load embeddings as required by the configuration automatically\n","- calculate sentence embeddings from word embeddings using a simple average\n","- calculate TF-IDF weighted word embeddings to help prioritise important words in the mean vector (sentence embedding)\n","\n"],"metadata":{"id":"5WFWtC_7g8RK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rsJi23vacEIY"},"outputs":[],"source":["\"\"\"\n","Embedding loader to help load different embeddings\n","from gensim, and apply them on the data frame in \n","different ways\n","\"\"\"\n","class EmbeddingLoader:\n","    def __init__(self, embedding_name: str, logger):\n","        self.logger = logger\n","        self.embeddings = api.load(embedding_name)\n","\n","    def embed(self, sentence):\n","        valid_words = [word for word in sentence if word in self.embeddings.key_to_index]\n","        # embedded = [self.embeddings[word] for word in valid_words]\n","        embedded = []\n","        for word in sentence:\n","            if word in self.embeddings.key_to_index:\n","                embedded.append(self.embeddings[word])\n","            else:\n","                embedded.append(np.zeros_like(self.embeddings['hello']))\n","\n","        embedded = np.array(embedded)\n","        hit_rate = len(valid_words)/len(sentence)\n","        self.logger.log (f\"Dimension of embedded array: {embedded.shape}, hit rate: {hit_rate}\")\n","        return embedded, hit_rate\n","\n","    def get_mean(self, sentence):\n","        valid_words = [word for word in sentence if word in self.embeddings.key_to_index]\n","        hit_rate = len(valid_words)/len(sentence)\n","        self.logger.log(f\"Hit rate: {hit_rate}\")\n","        return self.embeddings.get_mean_vector(valid_words)\n","\n","    def get_tf_idf_weighted_mean(self, all_plots, tf_idf_vecs):\n","        vec_rep = []\n","        total_hit_rate = 0\n","        for i, plot in enumerate(all_plots):\n","            scores = tf_idf_vecs[i, :len(plot)]\n","            vectors, hit_rate = self.embed(plot)\n","            total_hit_rate += hit_rate\n","            self.logger.log(f\"Hit rate: {hit_rate}\")\n","            self.logger.log(f\"Vectors shape: {vectors.shape}\")\n","\n","            n_vecs = vectors.shape[0]\n","            assert len(scores) == n_vecs\n","            weighted_mean = torch.zeros(vectors[0].shape)\n","            for j in range(n_vecs):\n","                weighted_mean = weighted_mean + (scores[j] * vectors[j])\n","\n","            vec_rep.append(np.array(weighted_mean))\n","\n","        self.logger.log(f\"Overall hit rate: {total_hit_rate/len(all_plots)}\")\n","        return torch.tensor(np.array(vec_rep))\n"]},{"cell_type":"markdown","source":["We are now ready to apply the concepts to the dataset, so we wrap the dataset with a reader class that reads the source dataset and performs the following transformations:\n","\n","- Applying sentence cleaning \n","- Applying down sampling on each class if configured\n","- Transforming sentence to embeddings using TF-IDF or simple average"],"metadata":{"id":"5j4zz59GiAbI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"58C1eXBIcCpY"},"outputs":[],"source":["\"\"\"\n","Dataset reader to read the dataset from file\n","and perform transformations (vectorization)\n","on the source data\n","\"\"\"\n","class DatasetReader:\n","    def __init__(self, embedding_type, logger, sent_cleaner_conf=None, down_sample_conf=None):\n","        if sent_cleaner_conf is None:\n","            sent_cleaner_conf = get_default_sent_cleaner_conf()\n","        if down_sample_conf is None:\n","            down_sample_conf = get_default_down_sample_conf()\n","\n","        # Member assignments\n","        self.logger = logger\n","        self.embedding_loader = EmbeddingLoader(embedding_type, logger)\n","        self.sent_cleaner_conf = sent_cleaner_conf\n","        self.down_sample_conf = down_sample_conf\n","\n","    def read(self, path_to_zip, simple, model_name):\n","        # Reading from zip files, and storing in a dictionary with key is fim genre,\n","        # and value is list of films with plot\n","        initial_df = pd.DataFrame()\n","\n","        with zipfile.ZipFile(path_to_zip) as z:\n","            for name in z.namelist():\n","                if name.endswith(\".csv\"):\n","                    self.logger.log(f'Loading data from {name}...')\n","                    x = pd.read_csv(z.open(name))\n","                    self.logger.log(f'Loading completed from {name}...')\n","                    initial_df = pd.concat([initial_df, x[['genre', 'plot']]], axis=0, ignore_index=True)\n","            self.logger.log(\"Dataframe (df) ready to be used!\")\n","\n","        df = self._down_sample(initial_df)\n","        df = df.dropna()\n","\n","        # Shuffle the df\n","        df = df.sample(frac=1)\n","\n","        self.logger.log(df['genre'].value_counts())\n","        Analytics.plot_value_counts(df, model_name, \"full\")\n","        if simple:\n","            self.logger.log(\"Preparing vectors using simple average\")\n","            return self._prepare_dataset(df)\n","        else:\n","            self.logger.log(\"Preparing vectors using weighted TF-IDF average\")\n","            return self._prepare_dataset_tfidf(df)\n","\n","    def _down_sample(self, df):\n","        # Down sample drama\n","        for genre in FILMS_GENRE:\n","            sample_percent = self.down_sample_conf.get(genre, 0.0)\n","            df = df.drop(df.query(f\"genre == '{genre}'\").sample(frac=sample_percent).index)\n","\n","        self.logger.log(df['genre'].value_counts())\n","        return df\n","\n","    def _prepare_dataset(self, df):\n","        # Clean the plots\n","        cleaned_plots = df['plot'].apply(lambda x: SentCleaner(x, self.sent_cleaner_conf).clean_sent())\n","        # Create the mean embedding vector\n","        embed_vectors = torch.tensor(np.array([self.embedding_loader.get_mean(plot) for plot in list(cleaned_plots)]))\n","        X = embed_vectors\n","        self.logger.log (f\"Mean vector result shape (embed_vectors) for {len(cleaned_plots)} plots: {embed_vectors.shape}\")\n","\n","        Y = torch.tensor(np.array(df['genre'].apply(lambda g: TARGET_LKP[g])))\n","\n","        self.logger.log(f\"Shape of X: {X.shape}\")\n","        self.logger.log(f\"Shape of Y: {Y.shape}\")\n","\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n","\n","        Analytics.show_train_val_test_stats(y_train, y_val, y_test, self.logger)\n","\n","        return X_train, X_test, y_train, y_test, X_val, y_val\n","\n","    # Limitation: separate tfidf for test set\n","    def _prepare_dataset_tfidf(self, df):\n","        # Clean the plots\n","        cleaned_plots = df['plot'].apply(lambda x: SentCleaner(x, self.sent_cleaner_conf).clean_sent())\n","\n","        # Calculate TFIDF\n","        tf_idf_vecs = TfIdfWeighter(cleaned_plots).get_tf_idf()\n","        embed_vectors = self.embedding_loader.get_tf_idf_weighted_mean(cleaned_plots, tf_idf_vecs)\n","\n","        X = embed_vectors\n","        self.logger.log (f\"Mean vector result shape (embed_vectors) for {len(cleaned_plots)} plots: {embed_vectors.shape}\")\n","        Y = torch.tensor(np.array(df['genre'].apply(lambda g: TARGET_LKP[g])))\n","\n","        self.logger.log(f\"Shape of X: {X.shape}\")\n","        self.logger.log(f\"Shape of Y: {Y.shape}\")\n","\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n","\n","        Analytics.show_train_val_test_stats(y_train, y_val, y_test, self.logger)\n","\n","        return X_train, X_test, y_train, y_test, X_val, y_val\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gPkb-YYHhXMx"},"source":["## Model framework"]},{"cell_type":"markdown","source":["The final remaining step is to create the models that we want to train on this dataset. As we would like to experiment with a lot of models, it is not practical to define them over and over. \n","\n","In this section we implement model structure parsing to help parse a model from its configuration.\n","\n","This framework parses the model structure from the configurations. For example, it takes ['l_50_100', 'r', 'd_0.5', ..] and creates a linear layer from 50 - 100 units, followed by relu and a dropout layer with probability 0.5.\n"],"metadata":{"id":"-CTeUsIYbhpx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E80zv55lhWM4"},"outputs":[],"source":["\"\"\"\n","Framework to automatically parse a MLP model \n","from a text configuration\n","\"\"\"\n","class ModelSpecParser:\n","    def __init__(self, spec, dim):\n","        self.dim = dim\n","        self.seq = None\n","        self.parse(spec)\n","        summary(self.seq, (1, dim))\n","\n","    def parse(self, spec):\n","        self.seq = nn.Sequential()\n","        _seq = []\n","\n","        for layer in spec:\n","            parts = layer.split('_')\n","\n","            if parts[0] == 'l':\n","                # Linear layer\n","                assert len(parts) == 3\n","                _seq.append(nn.Linear(int(parts[1]), int(parts[2])))\n","            elif parts[0] == 'd':\n","                # Dropout layer\n","                assert len(parts) == 2\n","                _seq.append(nn.Dropout(p=float(parts[1])))\n","            elif parts[0] == 's':\n","                # Softmax layer\n","                assert len(parts) == 2\n","                _seq.append(nn.Softmax(dim=int(parts[1])))\n","            elif parts[0] == 'r':\n","                # ReLU layer\n","                assert len(parts) == 1\n","                _seq.append(nn.ReLU())\n","            elif parts[0] == 'bn':\n","                assert len(parts) == 2\n","                _seq.append(nn.B)\n","\n","        self.seq = nn.Sequential(*_seq)"]},{"cell_type":"markdown","source":["We now wrap the basic functionality over nn.Module and build our model on top of this. We implement the following features here:\n","\n","- Checkpointing (as an alternative to early stopping)\n","- Forward, loss and backward\n","- Analytics during training\n","- Collect metrics on the training itself"],"metadata":{"id":"GxqxaXzHjJEq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wKy8DGDKiAEM"},"outputs":[],"source":["\"\"\"\n","Wrap basic model parsing functionality in a \n","basic deep learning model class\n","\"\"\"\n","class BasicDeepLearner(nn.Module):\n","    def __init__(self, model_spec, alpha, input_dim):\n","        super().__init__()\n","        self.seq = ModelSpecParser(model_spec, input_dim).seq\n","        self.alpha = alpha"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IqJm84F3iJ7K"},"outputs":[],"source":["\"\"\"\n","Implementation of simple MLP model training and testing\n","framework\n","\"\"\"\n","\n","class SimpleMLPTextClassifier(BasicDeepLearner):\n","    def __init__(self, checkpoint_freq, loss_fn, model_spec, name, sent_cleaner_conf, device, input_dim, batch_size, logger, alpha=1e-4):\n","        super().__init__(model_spec, alpha, input_dim)\n","        self.logger = logger\n","        self.loss_fn = loss_fn\n","        self.alpha = alpha\n","        self.checkpoint_freq = checkpoint_freq\n","        self.name = name\n","        self.sent_cleaner_conf = sent_cleaner_conf\n","        self.device = device\n","        self.train_csv = open(f\"outputs/{self.name}/train.csv\", \"w\")\n","        self.metrics_csv = open(f\"outputs/{self.name}/metrics.csv\", \"w\")\n","        self.start_time = None\n","        self.end_time = None\n","        self.bs = batch_size\n","\n","    def __init_csvs(self):\n","        self.train_csv.write(\"epoch,train_loss,val_loss,val_acc\\n\")\n","        self.metrics_csv.write(\"epoch,duration\\n\")\n","\n","    def forward(self, X_batch):\n","        return self.seq(X_batch)\n","\n","    def save_checkpoint(self, optimizer, curr_epoch, model_path, loss):\n","        self.logger.log(f\"Saving checkpoint to {model_path}\")\n","        torch.save({\n","            'epoch': curr_epoch,\n","            'model_state_dict': self.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': loss,\n","        }, model_path)\n","\n","    def run_training(self, train_x, train_y, val_x, val_y, optim, epochs=10):\n","        # self.train()\n","        start_time = time.process_time()\n","\n","        for e in range(0, epochs):\n","            _start = time.process_time()\n","            losses = self._training(train_x, train_y, optim)\n","\n","            # Save model checkpoint\n","            mean_loss = torch.tensor(losses).mean()\n","            if e > 0 and e % self.checkpoint_freq == 0:\n","                os.makedirs(f\"outputs/{self.name}/checkpoints\", exist_ok=True)\n","                self.save_checkpoint(optim, e, f'outputs/{self.name}/checkpoints/epoch-{e}.pt', mean_loss)\n","\n","            self.cal_loss_and_accuracy(val_x, val_y, mean_loss, e)\n","\n","            _end = time.process_time()\n","            self.metrics_csv.write(f\"{e},{_end-_start}\\n\")\n","            self.metrics_csv.flush()\n","\n","        Analytics.create_animated_gifs(self.name)\n","        end_time = time.process_time()\n","        duration = end_time - start_time\n","        self.logger.log(f\"Training time: {duration}\")\n","\n","    def _training(self, train_x, train_y, optim):\n","        losses = []\n","        # for X, Y in zip(torch.Tensor(train_x), torch.Tensor(train_y)):\n","        for row in range(0, train_x.shape[0], self.bs):\n","            X = train_x[row: row+self.bs]\n","            Y = train_y[row: row+self.bs]\n","            b = X.shape[0]\n","            Y_preds = self.forward(X)\n","\n","            loss = self.loss_fn(Y_preds.view(b, 10), Y.view(b))\n","            losses.append(loss.item())\n","\n","            optim.zero_grad()\n","            loss.backward()\n","            optim.step()\n","\n","        return losses\n","\n","    def cal_loss_and_accuracy(self, val_x, val_y, train_loss, epoch_num):\n","        with torch.no_grad():\n","            Y_shuffled, Y_preds, losses = [], [], []\n","            for i in range(val_x.shape[0]):\n","                X = val_x[i]\n","                Y = val_y[i]\n","                preds = self.forward(X)\n","                loss = self.loss_fn(preds.view(-1, 10), Y.view(1))\n","                losses.append(loss.item())\n","\n","                Y_shuffled.append(Y.view(1))\n","                Y_preds.append(preds.argmax(dim=-1))\n","\n","            Y_shuffled = torch.stack(Y_shuffled)\n","            Y_preds = torch.stack(Y_preds)\n","\n","            # Check confusion matrix\n","            Analytics.confusion_matrix_analysis(Y_shuffled, Y_preds, self.name, epoch_num)\n","\n","            # Check error by class\n","            Analytics.acc_by_class(Y_shuffled, Y_preds, self.name, epoch_num)\n","\n","            self.train_csv.write(f\"{epoch_num},{train_loss},{torch.tensor(losses).mean()},{accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())}\\n\")\n","            self.train_csv.flush()\n","            self.logger.log(\"Epoch: {:d} | Train Loss: {:.3f} | Valid Loss : {:.3f} | Valid Acc  : {:.3f}\"\n","                            .format(epoch_num, train_loss, torch.tensor(losses).mean(),\n","                                    accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n"]},{"cell_type":"markdown","source":["### Experiments\n"],"metadata":{"id":"CnDC4b31qNG8"}},{"cell_type":"markdown","source":["Finally, we define a model run flow and error handling in case we decide to interrupt the model for any reason. If we decide to stop the training, it still evaluates it on the test set.\n","\n","As this part takes a significant amount of time, we run it offline on a server and collect the results.\n","\n","Here we run the experiments to show some results and collect the outputs."],"metadata":{"id":"nM9V6xvyjemu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ap_YdQaRjA92"},"outputs":[],"source":["\"\"\"\n","Run a model from start to end with error handling\n","\"\"\"\n","IGNORE_VAL = 11.111\n","\n","def run_model(structure, model_name, lr, epochs, input_dim, batch_size, logger, X_train, y_train, X_val, y_val, X_test, y_test):\n","    # Define and run the model\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    loss_fn = nn.CrossEntropyLoss()\n","    model = SimpleMLPTextClassifier(checkpoint_freq=20, loss_fn=loss_fn,\n","                                    model_spec=structure, name=model_name,\n","                                    sent_cleaner_conf=None, device=device, input_dim=input_dim, batch_size=batch_size, logger=_logger, alpha=lr)\n","    try:\n","        optim = torch.optim.Adam(model.parameters(), lr=lr)\n","        model.run_training(X_train, y_train, X_val, y_val, optim, epochs=epochs)\n","\n","        logger.log(\"Next line is test loss - ignore the train loss there\")\n","        model.cal_loss_and_accuracy(X_test, y_test, IGNORE_VAL, 0)\n","\n","        return 0\n","    except KeyboardInterrupt:\n","        logger.log('Stopped - Next line is test loss - ignore the train loss there')\n","        model.cal_loss_and_accuracy(X_test, y_test, IGNORE_VAL, 0)\n","        return 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NNW9QURqjLyi","executionInfo":{"status":"ok","timestamp":1668605241447,"user_tz":-480,"elapsed":3770680,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"450e3d2d-c0fd-4d50-d41d-0e61ac504683"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1tNu5VVyNMGWkD9BQtI29mqLM3pW7g-1t\n","To: /content/config.json\n","\r  0% 0.00/8.77k [00:00<?, ?B/s]\r100% 8.77k/8.77k [00:00<00:00, 11.6MB/s]\n","Number of experiments: 17\n","Starting with model 0: first-model-batch-base with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-base', 'structure': ['l_50_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 250, 'input_dim': 50, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-50', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]           6,375\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 66,720\n","Trainable params: 66,720\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.25\n","Estimated Total Size (MB): 0.27\n","----------------------------------------------------------------\n","Starting with model 1: first-model-batch-base-tfidf-weighted with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-base-tfidf-weighted', 'structure': ['l_50_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 250, 'input_dim': 50, 'batch_size': 16, 'simple': False, 'embedding_type': 'glove-wiki-gigaword-50', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]           6,375\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 66,720\n","Trainable params: 66,720\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.25\n","Estimated Total Size (MB): 0.27\n","----------------------------------------------------------------\n","Starting with model 2: first-model-batch-dropout-0 with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-dropout-0', 'structure': ['l_50_125', 'r', 'l_125_125', 'r', 'l_125_150', 'r', 'l_150_110', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 200, 'input_dim': 50, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-50', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]           6,375\n","              ReLU-2               [-1, 1, 125]               0\n","            Linear-3               [-1, 1, 125]          15,750\n","              ReLU-4               [-1, 1, 125]               0\n","            Linear-5               [-1, 1, 150]          18,900\n","              ReLU-6               [-1, 1, 150]               0\n","            Linear-7               [-1, 1, 110]          16,610\n","              ReLU-8               [-1, 1, 110]               0\n","            Linear-9                [-1, 1, 75]           8,325\n","           Linear-10                [-1, 1, 10]             760\n","          Softmax-11                [-1, 1, 10]               0\n","================================================================\n","Total params: 66,720\n","Trainable params: 66,720\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.25\n","Estimated Total Size (MB): 0.26\n","----------------------------------------------------------------\n","Starting with model 3: first-model-batch-dropout-5 with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-dropout-5', 'structure': ['l_50_125', 'd_0.5', 'r', 'l_125_125', 'd_0.5', 'r', 'l_125_150', 'd_0.5', 'r', 'l_150_110', 'd_0.5', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 200, 'input_dim': 50, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-50', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]           6,375\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 66,720\n","Trainable params: 66,720\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.25\n","Estimated Total Size (MB): 0.27\n","----------------------------------------------------------------\n","Starting with model 4: first-model-batch-lre4 with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-lre4', 'structure': ['l_50_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 200, 'input_dim': 50, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-50', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]           6,375\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 66,720\n","Trainable params: 66,720\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.25\n","Estimated Total Size (MB): 0.27\n","----------------------------------------------------------------\n","Starting with model 5: first-model-batch-lre3 with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-lre3', 'structure': ['l_50_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.003, 'epochs': 200, 'input_dim': 50, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-50', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]           6,375\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 66,720\n","Trainable params: 66,720\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.25\n","Estimated Total Size (MB): 0.27\n","----------------------------------------------------------------\n","Starting with model 6: first-model-batch-lre2 with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-lre2', 'structure': ['l_50_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.03, 'epochs': 200, 'input_dim': 50, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-50', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]           6,375\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 66,720\n","Trainable params: 66,720\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.25\n","Estimated Total Size (MB): 0.27\n","----------------------------------------------------------------\n","Starting with model 7: first-model-batch-lre1 with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-lre1', 'structure': ['l_50_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.3, 'epochs': 200, 'input_dim': 50, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-50', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]           6,375\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 66,720\n","Trainable params: 66,720\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.25\n","Estimated Total Size (MB): 0.27\n","----------------------------------------------------------------\n","Starting with model 8: first-model-batch-emb-50 with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-emb-50', 'structure': ['l_50_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 200, 'input_dim': 50, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-50', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]           6,375\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 66,720\n","Trainable params: 66,720\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.25\n","Estimated Total Size (MB): 0.27\n","----------------------------------------------------------------\n","Starting with model 9: first-model-batch-emb-100 with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-emb-100', 'structure': ['l_100_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 200, 'input_dim': 100, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-100', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","[==================================================] 100.0% 128.1/128.1MB downloaded\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]          12,625\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 72,970\n","Trainable params: 72,970\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.28\n","Estimated Total Size (MB): 0.29\n","----------------------------------------------------------------\n","Starting with model 10: first-model-batch-emb-300 with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-emb-300', 'structure': ['l_300_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 200, 'input_dim': 300, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-300', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","[=================================================-] 99.5% 374.2/376.1MB downloaded\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]          37,625\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 97,970\n","Trainable params: 97,970\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.37\n","Estimated Total Size (MB): 0.39\n","----------------------------------------------------------------\n","Starting with model 11: first-model-batch-base-embedding-w2v-simple with config:\n","{'data_path': 'source_data/data_full3.zip', 'model_name': 'first-model-batch-base-embedding-w2v-simple', 'structure': ['l_300_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 200, 'input_dim': 300, 'batch_size': 16, 'simple': True, 'embedding_type': 'word2vec-google-news-300', 'down_sample': {'drama': 0.0, 'comedy': 0.0}}\n","[==============================================----] 92.3% 1534.0/1662.8MB downloadedInterrupted - quitting\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}],"source":["\"\"\"\n","Configurations \n","\"\"\"\n","# Fetch the configuration file that defines the experiments and begin\n","!rm config.json\n","!gdown 1tNu5VVyNMGWkD9BQtI29mqLM3pW7g-1t\n","!mkdir source_data \n","!cp data_full3.zip source_data/ \n","\n","configs = get_configs(\"config.json\")\n","print(f\"Number of experiments: {len(configs)}\")\n","\n","LOGFILE = \"training_log.txt\"\n","OUTPUT_DIR = \"/content/outputs\"\n","\n","for idx_config, config in enumerate(configs):\n","    try:\n","        print(f\"Starting with model {idx_config}: {config['model_name']} with config:\\n{config}\")\n","        os.makedirs(f\"outputs/{config['model_name']}\", exist_ok=True)\n","        _logger = Logger(f\"{OUTPUT_DIR}/{config['model_name']}\", LOGFILE, \"mlp_clf.py\")\n","\n","        dataset_reader = DatasetReader(config['embedding_type'], _logger)\n","        _X_train, _X_test, _y_train, _y_test, _X_val, _y_val = dataset_reader.read(config['data_path'], config['simple'], config['model_name'])\n","        outcome = run_model(config['structure'], config['model_name'], config['lr'], config['epochs'], config['input_dim'], config['batch_size'], _logger, _X_train, _y_train, _X_val, _y_val, _X_test, _y_test)\n","\n","        if outcome == 0:\n","            _logger.log (\"Completed training and testing\")\n","        else:\n","            _logger.log (\"Failed\")\n","    except KeyboardInterrupt as ke:\n","        print(\"Interrupted - quitting\")\n","        break\n","    except Exception as e:\n","        print(\"Failed the previous run. Trying the next\")\n","        print (e)        "]},{"cell_type":"markdown","source":["## Results and Analysis"],"metadata":{"id":"NpaSYCTzqV1N"}},{"cell_type":"markdown","source":["The results are neatly produced so that we are able to share the results with others as required. The `outputs/` directory contains one directory per model, and contains the results in the structure:\n","\n","-`outputs`\n","  - `{model_name}`\n","      - `checkpoints/` \n","      - `confusion/`\n","      - `acc_by_class/`\n","      - `full_value_counts.png`\n","      - `metrics.csv`\n","      - `train.csv`\n","      - `training_log.txt`\n","\n","These results can be used to understand the run fully after it has completed, and at each epoch the confusion and accuracies by class are stored. "],"metadata":{"id":"FEHHrqGirXzr"}},{"cell_type":"markdown","source":["We look at the following results from one good run:\n","\n"],"metadata":{"id":"_MehCE3VuDEN"}},{"cell_type":"code","source":["# Let us zip the output directory so that it can be downloaded if desired\n","!zip -r outputs.zip /content/outputs"],"metadata":{"id":"o1wppEuXxHZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let us view test loss from the \n","!tail -5 /content/outputs/first-model-batch-base/training_log.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZ_lS_39kl86","executionInfo":{"status":"ok","timestamp":1668559070900,"user_tz":-480,"elapsed":439,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"a39fff67-8db1-47fe-8dfd-73353d6537cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["16/11/2022 00:20:46: Epoch: 199 | Train Loss: 2.070 | Valid Loss : 2.137 | Valid Acc  : 0.312\n","16/11/2022 00:20:49: Training time: 195.5436655200001\n","16/11/2022 00:20:49: Next line is test loss - ignore the train loss there\n","16/11/2022 00:20:49: Epoch: 0 | Train Loss: 11.111 | Valid Loss : 2.109 | Valid Acc  : 0.341\n","16/11/2022 00:20:49: Completed training and testing\n"]}]},{"cell_type":"code","source":["# Let us see the checkpoints and the accuracies\n","print (\"Contents of the output directory\")\n","!ls -lrt /content/outputs/first-model-batch-base\n","!ls -lrt /content/outputs/first-model-batch-base/checkpoints"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8I5wqRHzman","executionInfo":{"status":"ok","timestamp":1668558131834,"user_tz":-480,"elapsed":541,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"441212ab-33f4-42f3-f7c3-e318351df858"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Contents of the output directory\n","total 196\n","-rw-r--r-- 1 root root   9631 Nov 16 00:17 full_value_counts.png\n","drwxr-xr-x 2 root root   4096 Nov 16 00:20 checkpoints\n","drwxr-xr-x 2 root root   4096 Nov 16 00:20 acc_by_class\n","-rw-r--r-- 1 root root   4461 Nov 16 00:20 metrics.csv\n","drwxr-xr-x 2 root root   4096 Nov 16 00:20 confusion\n","-rw-r--r-- 1 root root  12001 Nov 16 00:20 train.csv\n","-rw-r--r-- 1 root root 152561 Nov 16 00:20 training_log.txt\n","total 7164\n","-rw-r--r-- 1 root root 812882 Nov 16 00:17 epoch-20.pt\n","-rw-r--r-- 1 root root 812882 Nov 16 00:17 epoch-40.pt\n","-rw-r--r-- 1 root root 812882 Nov 16 00:18 epoch-60.pt\n","-rw-r--r-- 1 root root 812882 Nov 16 00:18 epoch-80.pt\n","-rw-r--r-- 1 root root 812882 Nov 16 00:18 epoch-100.pt\n","-rw-r--r-- 1 root root 812882 Nov 16 00:19 epoch-120.pt\n","-rw-r--r-- 1 root root 812882 Nov 16 00:19 epoch-140.pt\n","-rw-r--r-- 1 root root 812882 Nov 16 00:19 epoch-160.pt\n","-rw-r--r-- 1 root root 812882 Nov 16 00:20 epoch-180.pt\n"]}]},{"cell_type":"code","source":["# Lets see the models in descending order of test accuracy\n","models = os.listdir(\"/content/outputs\")\n","test_acc = [float(open(f\"/content/outputs/{m}/train.csv\").readlines()[-1].split(\",\")[-1]) for m in models]\n","sort_fn = lambda x: -x[1]\n","print (sorted(zip(models, acc), key=sort_fn))"],"metadata":{"id":"r2OhQq792AjT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We observe that the training is quite unstable and that results vary significantly for different initialization, random splits and parameter sets. Let us pick one good model to observe some training phenomena.\n","\n","In the cell below, we look at the confusion matrix of the validation predictions at each epoch. Looking at this, we are able to understand how the model is learning. \n","\n","Values accumulating on the leading diagonal indicates that the model is predicting those classes correctly. Rest of the cells show the different combinations of errors made by the model.\n","\n","We can see that the model starts off making a lot of errors related to comedy (could be due to the initialisation or the data batch/training split) and then proceeds to slowly move towards the diagonals as the epochs proceed."],"metadata":{"id":"_c_3dqlPaEX6"}},{"cell_type":"markdown","source":["As the training is quite unstable, we produce one artifact from our previous training that showed some promise. Our best test accuracy was 42%, though we were only able to consistently reproduce about 34%\n"],"metadata":{"id":"ylrO8nx8bwF7"}},{"cell_type":"code","source":["print (\"Confusion matrix over the epochs \")\n","from IPython.display import Image\n","Image(open('/content/outputs/first-model-batch-base/confusion/confusion.gif','rb').read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323,"output_embedded_package_id":"1dQKi28P0D-isdopGbXAy9anHu7NNUQ6e"},"id":"JgQUkKtFyPnW","executionInfo":{"status":"ok","timestamp":1668558198425,"user_tz":-480,"elapsed":5582,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"fce893db-eb1e-4906-a18a-3d6cf25c6404"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Next we look at the accuracy of the model in predicting each class. Our earlier suspicion is confirmed, and we can see that the model initially predicts comedy best because it almost always predicts comedy (high recall - low precision).\n","\n","As it sees more examples, it starts learning other parameters and is able to successfully predict others too."],"metadata":{"id":"IqaEjRaUa9WA"}},{"cell_type":"code","source":["def create_animated_gifs_acc(model_name):\n","    from PIL import Image\n","    Analytics.create_dirs_if_not_present(model_name)\n","    sort_fn = lambda x: int(os.path.basename(x).split('/')[-1].split('.')[0])\n","    images = [Image.open(image) for image in sorted(glob.glob(f\"/content/outputs/{model_name}/acc_by_class/*.png\"), key=sort_fn)]\n","    images[0].save(f\"/content/outputs/{model_name}/acc_by_class/accuracies.gif\", format=\"GIF\", append_images=images,\n","                    save_all=True, duration=len(images) / 2, loop=0)\n","\n","create_animated_gifs_acc(\"first-model-batch-base\")\n","print (\"Accuracies by class over the epochs \")\n","from IPython.display import Image\n","Image(open('/content/outputs/first-model-batch-base/acc_by_class/accuracies.gif','rb').read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323,"output_embedded_package_id":"1scMReFAoov_SuRcCIHOTO7k9Ehi8nLoE"},"id":"RgoS51yl0X8T","executionInfo":{"status":"ok","timestamp":1668558435883,"user_tz":-480,"elapsed":4065,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"fb38e8df-ad82-468f-c0e4-b402b958775c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Finally, we look at the training statistics to see how the training went. We can see a textbook run of the training and validation loss, seeing that the validation loss was starting to stagnate, as the training loss continued to drop. THe model stoppped at the perfect time."],"metadata":{"id":"mZ3CVc8PbWPN"}},{"cell_type":"code","source":["train_stats = pd.read_csv(\"/content/outputs/first-model-batch-base/train.csv\", header=None)\n","Analytics.plot_loss(train_stats[1][:-1], train_stats[2][:-1], \"first-model-batch-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"lE1qRIoF06CC","executionInfo":{"status":"ok","timestamp":1668558778251,"user_tz":-480,"elapsed":1258,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"8dcd1434-dda4-45d0-b971-db5cff36ad8c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Our best model reached about 42%"],"metadata":{"id":"C1slGxNtcO2n"}},{"cell_type":"markdown","source":["### 4-Class Problem"],"metadata":{"id":"Bl8DXfVVk9QZ"}},{"cell_type":"markdown","source":["Having now realised that we do not have enough training data for this 10 class problem, we retrain the model on a 4 class problem (using crime, romance, scifi and fantasy). The results are much better!\n","\n","We run the training 3 times to test the training stability."],"metadata":{"id":"V7ET56wdjIQ2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1u7UIGRyVLD"},"outputs":[],"source":["\"\"\"\n","Dataset reader to read the dataset from file\n","and perform transformations (vectorization)\n","on the source data\n","\"\"\"\n","class DatasetReader:\n","    def __init__(self, embedding_type, logger, sent_cleaner_conf=None, down_sample_conf=None):\n","        if sent_cleaner_conf is None:\n","            sent_cleaner_conf = get_default_sent_cleaner_conf_all_false()\n","        if down_sample_conf is None:\n","            down_sample_conf = get_default_down_sample_conf()\n","\n","        # Member assignments\n","        self.logger = logger\n","        self.embedding_loader = EmbeddingLoader(embedding_type, logger)\n","        self.sent_cleaner_conf = sent_cleaner_conf\n","        self.down_sample_conf = down_sample_conf\n","\n","    def read(self, path_to_zip, simple, model_name):\n","        # Reading from zip files, and storing in a dictionary with key is fim genre,\n","        # and value is list of films with plot\n","        initial_df = pd.DataFrame()\n","\n","        with zipfile.ZipFile(path_to_zip) as z:\n","            for name in z.namelist():\n","                if name.endswith(\".csv\"):\n","                    self.logger.log(f'Loading data from {name}...')\n","                    x = pd.read_csv(z.open(name))\n","                    self.logger.log(f'Loading completed from {name}...')\n","                    initial_df = pd.concat([initial_df, x[['genre', 'plot']]], axis=0, ignore_index=True)\n","                    if name.split('/')[-2] not in [\"scifi\", \"fantasy\", \"romance\", \"crime\"]:\n","                      initial_df = initial_df.drop(initial_df.query(f\"genre == '{name.split('/')[-2]}'\").index)\n","                    \n","            self.logger.log(\"Dataframe (df) ready to be used!\")\n","\n","        df = self._down_sample(initial_df)\n","        df = df.dropna()\n","\n","        # Shuffle the df\n","        df = df.sample(frac=1)\n","\n","        self.logger.log(df['genre'].value_counts())\n","        Analytics.plot_value_counts(df, model_name, \"full\")\n","        if simple:\n","            self.logger.log(\"Preparing vectors using simple average\")\n","            return self._prepare_dataset(df)\n","        else:\n","            self.logger.log(\"Preparing vectors using weighted TF-IDF average\")\n","            return self._prepare_dataset_tfidf(df)\n","\n","    def _down_sample(self, df):\n","        # Down sample drama\n","        for genre in FILMS_GENRE:\n","            sample_percent = self.down_sample_conf.get(genre, 0.0)\n","            df = df.drop(df.query(f\"genre == '{genre}'\").sample(frac=sample_percent).index)\n","\n","        self.logger.log(df['genre'].value_counts())\n","        return df\n","\n","    def _prepare_dataset(self, df):\n","        # Clean the plots\n","        cleaned_plots = df['plot'].apply(lambda x: SentCleaner(x, self.sent_cleaner_conf).clean_sent())\n","        # Create the mean embedding vector\n","        embed_vectors = torch.tensor(np.array([self.embedding_loader.get_mean(plot) for plot in list(cleaned_plots)]))\n","        X = embed_vectors\n","        self.logger.log (f\"Mean vector result shape (embed_vectors) for {len(cleaned_plots)} plots: {embed_vectors.shape}\")\n","\n","        Y = torch.tensor(np.array(df['genre'].apply(lambda g: TARGET_LKP[g])))\n","\n","        self.logger.log(f\"Shape of X: {X.shape}\")\n","        self.logger.log(f\"Shape of Y: {Y.shape}\")\n","\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n","\n","        Analytics.show_train_val_test_stats(y_train, y_val, y_test, self.logger)\n","\n","        return X_train, X_test, y_train, y_test, X_val, y_val\n","\n","    # Limitation: separate tfidf for test set\n","    def _prepare_dataset_tfidf(self, df):\n","        # Clean the plots\n","        cleaned_plots = df['plot'].apply(lambda x: SentCleaner(x, self.sent_cleaner_conf).clean_sent())\n","\n","        # Calculate TFIDF\n","        tf_idf_vecs = TfIdfWeighter(cleaned_plots).get_tf_idf()\n","        embed_vectors = self.embedding_loader.get_tf_idf_weighted_mean(cleaned_plots, tf_idf_vecs)\n","\n","        X = embed_vectors\n","        self.logger.log (f\"Mean vector result shape (embed_vectors) for {len(cleaned_plots)} plots: {embed_vectors.shape}\")\n","        Y = torch.tensor(np.array(df['genre'].apply(lambda g: TARGET_LKP[g])))\n","\n","        self.logger.log(f\"Shape of X: {X.shape}\")\n","        self.logger.log(f\"Shape of Y: {Y.shape}\")\n","\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n","\n","        Analytics.show_train_val_test_stats(y_train, y_val, y_test, self.logger)\n","\n","        return X_train, X_test, y_train, y_test, X_val, y_val\n","\n"]},{"cell_type":"code","source":["# Download the final dataset\n","!gdown 1dhTF48AKpPBEq0ZeSstOSsS17A7ktmzl\n","\n","# Download new configurations\n","!gdown 1dUw3Lf0b998DSuY3z-ptEYfVVVawxV7Q\n","\n","# Fetch the data\n","!gdown 10fAkL5gOYjG0WcNIwZnZ1X9_n8pciT19\n","os.makedirs(\"/content/data/\", exist_ok=True)\n","!cp /content/data_full4.zip /content/data/\n","path = \"/content/data/data_full4.zip\"\n","\n","initial_df = pd.DataFrame()\n","with zipfile.ZipFile(path) as z:\n","  for name in z.namelist():\n","    print (name)\n","    print (name.split('/')[-2])\n","    if name.endswith(\".csv\"):\n","      print(f'Loading data from {name}...')\n","      x = pd.read_csv(z.open(name))\n","      print(f'Loading completed from {name}...')\n","      initial_df = pd.concat([initial_df,x[['genre','plot']]],axis=0,ignore_index=True)\n","\n","      if name.split('/')[-2] not in [\"scifi\", \"fantasy\", \"romance\", \"crime\"]:\n","        initial_df = initial_df.drop(initial_df.query(f\"genre == '{name.split('/')[-2]}'\").index)\n","\n","  print(\"Dataframe (df) ready to be used!\")\n","\n","initial_df\n","\n","print(initial_df['genre'].value_counts())\n","\n","\"\"\"\n","Configurations \n","\"\"\"\n","# Fetch the configuration file that defines the experiments and begin\n","!rm config.json\n","!gdown 1tNu5VVyNMGWkD9BQtI29mqLM3pW7g-1t\n","!mkdir source_data \n","!cp data_full3.zip source_data/ \n","\n","configs = get_configs(\"config-arch.json\")\n","print(f\"Number of experiments: {len(configs)}\")\n","\n","LOGFILE = \"training_log.txt\"\n","OUTPUT_DIR = \"/content/outputs\"\n","\n","for idx_config, config in enumerate(configs):\n","    try:\n","        print(f\"Starting with model {idx_config}: {config['model_name']} with config:\\n{config}\")\n","        os.makedirs(f\"outputs/{config['model_name']}\", exist_ok=True)\n","        _logger = Logger(f\"{OUTPUT_DIR}/{config['model_name']}\", LOGFILE, \"mlp_clf.py\")\n","\n","        dataset_reader = DatasetReader(config['embedding_type'], _logger)\n","        _X_train, _X_test, _y_train, _y_test, _X_val, _y_val = dataset_reader.read(config['data_path'], config['simple'], config['model_name'])\n","        outcome = run_model(config['structure'], config['model_name'], config['lr'], config['epochs'], config['input_dim'], config['batch_size'], _logger, _X_train, _y_train, _X_val, _y_val, _X_test, _y_test)\n","\n","        if outcome == 0:\n","            _logger.log (\"Completed training and testing\")\n","        else:\n","            _logger.log (\"Failed\")\n","    except KeyboardInterrupt as ke:\n","        print(\"Interrupted - quitting\")\n","        break\n","    except Exception as e:\n","        print(\"Failed the previous run. Trying the next\")\n","        print (e)        "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vTHkOTgkcdzq","executionInfo":{"status":"ok","timestamp":1668609678192,"user_tz":-480,"elapsed":678789,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"5d2da875-3aa6-4027-b4c8-8c15c1b71f1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1dhTF48AKpPBEq0ZeSstOSsS17A7ktmzl\n","To: /content/data_full4.zip\n","100% 7.18M/7.18M [00:00<00:00, 145MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1dUw3Lf0b998DSuY3z-ptEYfVVVawxV7Q\n","To: /content/config-arch.json\n","100% 2.15k/2.15k [00:00<00:00, 2.71MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=10fAkL5gOYjG0WcNIwZnZ1X9_n8pciT19\n","To: /content/data_full3.zip\n","100% 5.15M/5.15M [00:00<00:00, 200MB/s]\n","content/gdrive/MyDrive/CS5242_Project_Data_2/action/action_films.csv\n","action\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data_2/action/action_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data_2/action/action_films.csv...\n","content/gdrive/MyDrive/CS5242_Project_Data_2/adventure/adventure_films.csv\n","adventure\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data_2/adventure/adventure_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data_2/adventure/adventure_films.csv...\n","content/gdrive/MyDrive/CS5242_Project_Data_2/comedy/comedy_films.csv\n","comedy\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data_2/comedy/comedy_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data_2/comedy/comedy_films.csv...\n","content/gdrive/MyDrive/CS5242_Project_Data_2/drama/drama_films.csv\n","drama\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data_2/drama/drama_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data_2/drama/drama_films.csv...\n","content/gdrive/MyDrive/CS5242_Project_Data_2/horror/horror_films.csv\n","horror\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data_2/horror/horror_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data_2/horror/horror_films.csv...\n","content/gdrive/MyDrive/CS5242_Project_Data_2/romance/romance_films.csv\n","romance\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data_2/romance/romance_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data_2/romance/romance_films.csv...\n","content/gdrive/MyDrive/CS5242_Project_Data_2/scifi/scifi_films.csv\n","scifi\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data_2/scifi/scifi_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data_2/scifi/scifi_films.csv...\n","content/gdrive/MyDrive/CS5242_Project_Data_2/fantasy/fantasy_films.csv\n","fantasy\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data_2/fantasy/fantasy_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data_2/fantasy/fantasy_films.csv...\n","content/gdrive/MyDrive/CS5242_Project_Data_2/historical/historical_films.csv\n","historical\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data_2/historical/historical_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data_2/historical/historical_films.csv...\n","content/gdrive/MyDrive/CS5242_Project_Data_2/crime/crime_films.csv\n","crime\n","Loading data from content/gdrive/MyDrive/CS5242_Project_Data_2/crime/crime_films.csv...\n","Loading completed from content/gdrive/MyDrive/CS5242_Project_Data_2/crime/crime_films.csv...\n","Dataframe (df) ready to be used!\n","crime      425\n","scifi      316\n","fantasy    206\n","romance    156\n","Name: genre, dtype: int64\n","Downloading...\n","From: https://drive.google.com/uc?id=1tNu5VVyNMGWkD9BQtI29mqLM3pW7g-1t\n","To: /content/config.json\n","100% 8.77k/8.77k [00:00<00:00, 11.1MB/s]\n","mkdir: cannot create directory â€˜source_dataâ€™: File exists\n","Number of experiments: 3\n","Starting with model 0: first-model-batch-4clf-1 with config:\n","{'data_path': 'data/data_full4.zip', 'model_name': 'first-model-batch-4clf-1', 'structure': ['l_300_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 200, 'input_dim': 300, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-300', 'down_sample': {'action': 1.0, 'adventure': 1.0, 'comedy': 1.0, 'drama': 1.0, 'horror': 1.0, 'romance': 0.0, 'scifi': 0.0, 'fantasy': 0.0, 'historical': 1.0, 'crime': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]          37,625\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 97,970\n","Trainable params: 97,970\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.37\n","Estimated Total Size (MB): 0.39\n","----------------------------------------------------------------\n","Starting with model 1: first-model-batch-4clf-2 with config:\n","{'data_path': 'data/data_full4.zip', 'model_name': 'first-model-batch-4clf-2', 'structure': ['l_300_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 200, 'input_dim': 300, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-300', 'down_sample': {'action': 1.0, 'adventure': 1.0, 'comedy': 1.0, 'drama': 1.0, 'horror': 1.0, 'romance': 0.0, 'scifi': 0.0, 'fantasy': 0.0, 'historical': 1.0, 'crime': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]          37,625\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 97,970\n","Trainable params: 97,970\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.37\n","Estimated Total Size (MB): 0.39\n","----------------------------------------------------------------\n","Starting with model 2: first-model-batch-4clf-3 with config:\n","{'data_path': 'data/data_full4.zip', 'model_name': 'first-model-batch-4clf-3', 'structure': ['l_300_125', 'd_0.3', 'r', 'l_125_125', 'd_0.3', 'r', 'l_125_150', 'd_0.3', 'r', 'l_150_110', 'd_0.3', 'r', 'l_110_75', 'l_75_10', 's_0'], 'lr': 0.0003, 'epochs': 200, 'input_dim': 300, 'batch_size': 16, 'simple': True, 'embedding_type': 'glove-wiki-gigaword-300', 'down_sample': {'action': 1.0, 'adventure': 1.0, 'comedy': 1.0, 'drama': 1.0, 'horror': 1.0, 'romance': 0.0, 'scifi': 0.0, 'fantasy': 0.0, 'historical': 1.0, 'crime': 0.0}}\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1               [-1, 1, 125]          37,625\n","           Dropout-2               [-1, 1, 125]               0\n","              ReLU-3               [-1, 1, 125]               0\n","            Linear-4               [-1, 1, 125]          15,750\n","           Dropout-5               [-1, 1, 125]               0\n","              ReLU-6               [-1, 1, 125]               0\n","            Linear-7               [-1, 1, 150]          18,900\n","           Dropout-8               [-1, 1, 150]               0\n","              ReLU-9               [-1, 1, 150]               0\n","           Linear-10               [-1, 1, 110]          16,610\n","          Dropout-11               [-1, 1, 110]               0\n","             ReLU-12               [-1, 1, 110]               0\n","           Linear-13                [-1, 1, 75]           8,325\n","           Linear-14                [-1, 1, 10]             760\n","          Softmax-15                [-1, 1, 10]               0\n","================================================================\n","Total params: 97,970\n","Trainable params: 97,970\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.37\n","Estimated Total Size (MB): 0.39\n","----------------------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["# Let us view test loss from the 3 runs\n","!tail -5 /content/outputs/first-model-batch-4clf-1/training_log.txt\n","!tail -5 /content/outputs/first-model-batch-4clf-2/training_log.txt\n","!tail -5 /content/outputs/first-model-batch-4clf-3/training_log.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2fugMA3rtCR","executionInfo":{"status":"ok","timestamp":1668609678192,"user_tz":-480,"elapsed":12,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"b8e84a97-2301-4cef-e9b9-ab256e2d810e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["16/11/2022 14:33:48: Epoch: 199 | Train Loss: 2.143 | Valid Loss : 1.790 | Valid Acc  : 0.674\n","16/11/2022 14:33:50: Training time: 138.346734484001\n","16/11/2022 14:33:50: Next line is test loss - ignore the train loss there\n","16/11/2022 14:33:50: Epoch: 0 | Train Loss: 11.111 | Valid Loss : 1.834 | Valid Acc  : 0.624\n","16/11/2022 14:33:50: Completed training and testing\n","16/11/2022 14:37:42: Epoch: 199 | Train Loss: 2.142 | Valid Loss : 1.971 | Valid Acc  : 0.573\n","16/11/2022 14:37:44: Training time: 131.97618845800025\n","16/11/2022 14:37:44: Next line is test loss - ignore the train loss there\n","16/11/2022 14:37:44: Epoch: 0 | Train Loss: 11.111 | Valid Loss : 1.916 | Valid Acc  : 0.579\n","16/11/2022 14:37:44: Completed training and testing\n","16/11/2022 14:41:14: Epoch: 199 | Train Loss: 2.140 | Valid Loss : 1.930 | Valid Acc  : 0.539\n","16/11/2022 14:41:16: Training time: 131.2530084129994\n","16/11/2022 14:41:16: Next line is test loss - ignore the train loss there\n","16/11/2022 14:41:16: Epoch: 0 | Train Loss: 11.111 | Valid Loss : 1.843 | Valid Acc  : 0.629\n","16/11/2022 14:41:16: Completed training and testing\n"]}]},{"cell_type":"code","source":["train_stats = pd.read_csv(\"/content/outputs/first-model-batch-4clf-1/train.csv\", header=None)\n","Analytics.plot_loss(train_stats[1][:-1], train_stats[2][:-1], \"first-model-batch-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"66XqOzY12iNe","executionInfo":{"status":"ok","timestamp":1668609678193,"user_tz":-480,"elapsed":7,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"7e398d7f-7ff6-47ba-f34c-4fc39dea886c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAABUSUlEQVR4nO2dZ3hcxdWA36NudclqtmS5F9yLjDE2YNNCNzW0YEwNJKGEBEjyESChBAgEQgg1lFCCQy+hd2Mwrrj3brnIsmSr953vx9yrXcmSLFlaFe95n2ef2+bee+7d3Tlzzpk5I8YYFEVRlMAlqKMFUBRFUToWVQSKoigBjioCRVGUAEcVgaIoSoCjikBRFCXAUUWgKIoS4KgiUNoEEflIRC5t67IdiYhsFpHj/XDdr0XkSmf9YhH5tDllD+I+mSJSLCLBByurEhioIghgnErC/XhEpMxn++KWXMsYc7Ix5t9tXbYzIiK/E5FZDexPEpFKERne3GsZY14xxpzYRnLVUVzGmK3GmGhjTE1bXL/evYyIDGjr6yodgyqCAMapJKKNMdHAVuB0n32vuOVEJKTjpOyUvAwcKSJ96+2/AFhmjFneATIpykGjikDZDxGZIiLZInKriOwCnheRBBH5n4jkisheZz3D5xxfd8cMEZktIg86ZTeJyMkHWbaviMwSkSIR+VxE/ikiLzcid3NkvEtEvnOu96mIJPkcv0REtohInoj8X2PvxxiTDXwJXFLv0HTgxQPJUU/mGSIy22f7BBFZLSIFIvIYID7H+ovIl458e0TkFRGJd469BGQC7zsW3S0i0sdpuYc4ZXqKyHsiki8i60XkKp9r3ykir4nIi867WSEiWY29g8YQkTjnGrnOu7xNRIKcYwNE5Bvn2faIyH+d/SIiD4vIbhEpFJFlLbGqlNajikBpjDQgEegNXI39rTzvbGcCZcBjTZw/AVgDJAEPAM+KiBxE2f8A84DuwJ3sX/n60hwZLwIuA1KAMOC3ACIyFHjCuX5P534NVt4O//aVRUQGA6MdeVv6rtxrJAFvAbdh38UGYJJvEeAvjnyHAb2w7wRjzCXUteoeaOAWM4Fs5/xzgXtF5Fif42c4ZeKB95ojcwP8A4gD+gHHYJXjZc6xu4BPgQTsu/2Hs/9E4GhgkHPuT4G8g7i3crAYY/SjH4DNwPHO+hSgEohoovxoYK/P9tfAlc76DGC9z7FIwABpLSmLrUSrgUif4y8DLzfzmRqS8Taf7V8AHzvrtwMzfY5FOe/g+EauHQkUAkc62/cA7x7ku5rtrE8HfvApJ9iK+8pGrnsm8GND36Gz3cd5lyFYpVEDxPgc/wvwgrN+J/C5z7GhQFkT79YAA+rtC3be2VCffT8HvnbWXwSeBjLqnXcssBY4Agjq6P9CIH7UIlAaI9cYU+5uiEikiDzlmPuFwCwgXhrvkbLLXTHGlDqr0S0s2xPI99kHsK0xgZsp4y6f9VIfmXr6XtsYU0ITrVJHpteB6Y71cjG2ojuYd+VSXwbjuy0iqSIyU0S2O9d9GWs5NAf3XRb57NsCpPts1383EdKy+FASEOpct6F73IJVbvMc19PlAMaYL7HWxz+B3SLytIjEtuC+SitRRaA0Rv20tL8BBgMTjDGxWFMefHzYfmAnkCgikT77ejVRvjUy7vS9tnPP7gc4599YN8YJQAzwfivlqC+DUPd578V+LyOc6/6s3jWbSiW8A/suY3z2ZQLbDyBTS9gDVGFdYvvdwxizyxhzlTGmJ9ZSeFycnkfGmEeNMeOwlsgg4OY2lEs5AKoIlOYSg/V17xORROAOf9/QGLMFWADcKSJhIjIRON1PMr4BnCYik0UkDPgzB/5/fAvsw7o7ZhpjKlspxwfAMBE522mJX491kbnEAMVAgYiks39lmYP1ze+HMWYb8D3wFxGJEJGRwBVYq+JgCXOuFSEiEc6+14B7RCRGRHoDN7n3EJHzfILme7GKyyMi40VkgoiEAiVAOeBphVxKC1FFoDSXR4Bu2FbfD8DH7XTfi4GJWDfN3cB/gYpGyj7CQcpojFkB/BIb7N2JraiyD3COwbqDejvLVslhjNkDnAfch33egcB3PkX+BIwFCrBK4616l/gLcJuI7BOR3zZwiwuxcYMdwNvAHcaYz5sjWyOswCo893MZcB22Mt8IzMa+z+ec8uOBuSJSjA1G32CM2QjEAs9g3/kW7LP/tRVyKS1EnGCNonQJnC6Hq40xfrdIFCVQUItA6dQ4boP+IhIkIicB04B3OlgsRTmk0BGjSmcnDesC6Y511VxrjPmxY0VSlEMLdQ0piqIEOOoaUhRFCXC6nGsoKSnJ9OnTp6PFUBRF6VIsXLhwjzEmuaFjXU4R9OnThwULFnS0GIqiKF0KEdnS2DF1DSmKogQ4qggURVECHFUEiqIoAU6XixEoitI+VFVVkZ2dTXl5+YELK52GiIgIMjIyCA0NbfY5qggURWmQ7OxsYmJi6NOnD43PKaR0Jowx5OXlkZ2dTd++9WdSbRx1DSmK0iDl5eV0795dlUAXQkTo3r17i604vykCEeklIl+JyEpnEoobGigzTUSWishiEVkgIpP9JY+iKC1HlUDX42C+M3+6hqqB3xhjFjmTYSwUkc+MMSt9ynwBvGeMMU5+9NeAIf4QZm1OEf9bupMggSARQoOD6JsUxcR+3YmLbL4vTVEU5VDDb4rAGLMTm9cdY0yRiKzCTlm30qdMsc8pUTQ9w1Kr2LluCaHfPMN2k8R2k8R6Tzo76c5RA5N46YoJ/rqtoigHSV5eHscddxwAu3btIjg4mORkOzB23rx5hIWFNXruggULePHFF3n00UebfT93sGpSUnNn/zx0aJdgsYj0AcYAcxs4dhZ2Qo0U4NRGzr8auBogMzPzoGQ4Jn43x4S+D6YGABMUwoNpf+PNnIgDnKkoSkfQvXt3Fi9eDMCdd95JdHQ0v/2td76d6upqQkIarsKysrLIyspqDzEPCfweLBaRaOBN4EZjTGH948aYt40xQ4AzgbsauoYx5mljTJYxJsttEbSY4WfDbbvhxmUw4wMkPJazKt5mV2E55VU1B3dNRVHalRkzZnDNNdcwYcIEbrnlFubNm8fEiRMZM2YMRx55JGvWrAHg66+/5rTTTgOsErn88suZMmUK/fr1a5GVsHnzZo499lhGjhzJcccdx9atWwF4/fXXGT58OKNGjeLoo+2U1CtWrODwww9n9OjRjBw5knXr1rXx0/sPv1oEzhykbwKvGGPqT6tXB2PMLBHpJyJJzpR9bU9wCMRn2s+4GfSf/QgZcibZe8sYkBLtl1sqyqHAn95fwcod+7XjWsXQnrHccfqwFp+XnZ3N999/T3BwMIWFhXz77beEhITw+eef84c//IE333xzv3NWr17NV199RVFREYMHD+baa69tVj/76667jksvvZRLL72U5557juuvv5533nmHP//5z3zyySekp6ezb98+AJ588kluuOEGLr74YiorK6mp6ToNTH/2GhLgWWCVMeZvjZQZ4JRDRMYC4dj5Sv3P+CtBhOnBn7Itv7RdbqkoSus577zzCA4OBqCgoIDzzjuP4cOH8+tf/5oVK1Y0eM6pp55KeHg4SUlJpKSkkJOT06x7zZkzh4suugiASy65hNmzZwMwadIkZsyYwTPPPFNb4U+cOJF7772X+++/ny1bttCtW7fWPmq74U+LYBJwCbBMRBY7+/4AZAIYY54EzgGmi0gVdvLr8017zZQTl051zyxGb1vPKlUEitIkB9Ny9xdRUVG163/84x+ZOnUqb7/9Nps3b2bKlCkNnhMeHl67HhwcTHV1datkePLJJ5k7dy4ffPAB48aNY+HChVx00UVMmDCBDz74gFNOOYWnnnqKY489tlX3aS/82WtoNtBkh1ZjzP3A/f6S4UCEhEcSJvlsyVNFoChdkYKCAtLT0wF44YUX2vz6Rx55JDNnzuSSSy7hlVde4aijjgJgw4YNTJgwgQkTJvDRRx+xbds2CgoK6NevH9dffz1bt25l6dKlXUYRBPTIYgkOJTLEsFUtAkXpktxyyy38/ve/Z8yYMa1u5QOMHDmSjIwMMjIyuOmmm/jHP/7B888/z8iRI3nppZf4+9//DsDNN9/MiBEjGD58OEceeSSjRo3itddeY/jw4YwePZrly5czffr0VsvTXnS5OYuzsrJMm01M8+qFbN20hqu6PcInvz66ba6pKIcIq1at4rDDDutoMZSDoKHvTkQWGmMa7FMb0BYBQcFEBFmLoKspREVRlLYiwBVBKOFBHsqqathTXNnR0iiKonQIAa4IQggT2/VL4wSKogQqAa8IQsQDwNb8kg4WRlEUpWMIcEUQTAiOIsgr62BhFEVROobAVgTBoYipJi02Ql1DiqIELIGtCIJCoKaKzMRITTOhKJ2MqVOn8sknn9TZ98gjj3Dttdc2es6UKVNwu5efcsoptXmAfLnzzjt58MEHm7z3O++8w8qV3qlTbr/9dj7//PMWSN8wvsnwOhOqCDw19EqMVItAUToZF154ITNnzqyzb+bMmVx44YXNOv/DDz8kPj7+oO5dXxH8+c9/5vjjjz+oa3UFAlwRBIOnmt7dIzUdtaJ0Ms4991w++OADKitt1+7NmzezY8cOjjrqKK699lqysrIYNmwYd9xxR4Pn9+nThz17bCLje+65h0GDBjF58uTaVNUAzzzzDOPHj2fUqFGcc845lJaW8v333/Pee+9x8803M3r0aDZs2MCMGTN44403APjiiy8YM2YMI0aM4PLLL6eioqL2fnfccQdjx45lxIgRrF69utnP+uqrr9aOVL711lsBqKmpYcaMGQwfPpwRI0bw8MMPA/Doo48ydOhQRo4cyQUXXNDCt9ow7TIxTaclKBQ81WQmRgJoOmpFaYyPfge7lrXtNdNGwMn3NXo4MTGRww8/nI8++ohp06Yxc+ZMfvrTnyIi3HPPPSQmJlJTU8Nxxx3H0qVLGTlyZIPXWbhwITNnzmTx4sVUV1czduxYxo0bB8DZZ5/NVVddBcBtt93Gs88+y3XXXccZZ5zBaaedxrnnnlvnWuXl5cyYMYMvvviCQYMGMX36dJ544gluvPFGAJKSkli0aBGPP/44Dz74IP/6178O+Bp27NjBrbfeysKFC0lISODEE0/knXfeoVevXmzfvp3ly5cD1Lq57rvvPjZt2kR4eHiDrq+DIcAtghDwVNErwaaL1S6kitK58HUP+bqFXnvtNcaOHcuYMWNYsWJFHTdOfb799lvOOussIiMjiY2N5Ywzzqg9tnz5co466ihGjBjBK6+80mgaa5c1a9bQt29fBg0aBMCll17KrFmzao+fffbZAIwbN47Nmzc36xnnz5/PlClTSE5OJiQkhIsvvphZs2bRr18/Nm7cyHXXXcfHH39MbGwsYPMhXXzxxbz88suNztDWUgLcIrCPn5lgp6vcqllIFaVhmmi5+5Np06bx61//mkWLFlFaWsq4cePYtGkTDz74IPPnzychIYEZM2ZQXl5+UNefMWMG77zzDqNGjeKFF17g66+/bpW8brrrtkh1nZCQwJIlS/jkk0948sknee2113juuef44IMPmDVrFu+//z733HMPy5Yta7VCCHCLwE5ukRQZRLfQYLbm61gCRelMREdHM3XqVC6//PJaa6CwsJCoqCji4uLIycnho48+avIaRx99NO+88w5lZWUUFRXx/vvv1x4rKiqiR48eVFVV8corr9Tuj4mJoaioaL9rDR48mM2bN7N+/XoAXnrpJY455phWPePhhx/ON998w549e6ipqeHVV1/lmGOOYc+ePXg8Hs455xzuvvtuFi1ahMfjYdu2bUydOpX777+fgoICiouLW3V/CHSLINhOVSemhszESHUNKUon5MILL+Sss86qdRGNGjWKMWPGMGTIEHr16sWkSZOaPH/s2LGcf/75jBo1ipSUFMaPH1977K677mLChAkkJyczYcKE2sr/ggsu4KqrruLRRx+tDRIDRERE8Pzzz3PeeedRXV3N+PHjueaaa1r0PF988QUZGRm126+//jr33XcfU6dOxRjDqaeeyrRp01iyZAmXXXYZHo8d9PqXv/yFmpoafvazn1FQUIAxhuuvv/6ge0b5EthpqOf8Ez75A9y6hZve38xbi7Zz3JAU7j5rOOEhwdz2zjLOGJXOScPT2uZ+itKF0DTUXZeWpqEObIvAiRHgqeHOM4bROzGKp2dt4OJ/zSUpOpx5m/L5cNkubjhuINcdO4CQ4MD2pCmKcmgS4IrAxgjwVBMbFcoNxw9kYv/uXPLsXDbmlnD/OSOYt2kvf/9iHbPW5XLJEb0Z1jOOQanRiDQ5C6eiKEqXIcAVgY0R4PFG9w/vm8h/rppA9t4ypo1O5/zxmRwzOJk73l3OTa8tASA5JpyLJ2RyzTH9iQgN7gjJFaVdMMZoo6eLcTDu/gBXBK5rqKrO7nG9ExnX27t9xqienDw8jS15Jfy4dR+frNjFI5+v45W5W5kyKJnBaTEMTI3h6IFJ+qdRDhkiIiLIy8uje/fu+rvuIhhjyMvLIyIiokXnqSIA8Bw4tURocBADUmIYkBLDeVm9mLMhj39/v5lPV+bw+sJsAH538hDOHpvOvE35nDy8B8FB+udRui4ZGRlkZ2eTm5vb0aIoLSAiIqJOr6TmEOCKwBsjaCkT+3dnYv/uGGMoKKvij++u4L6PVvPwZ2upqPZw+aR93H760DYWWFHaj9DQUPr27dvRYijtQGArguD9YwQtRUSIjwzjwfNGEiwQEhxESJDw3HebKKmo5tjDUjjhsFREYN3uYvolRWnvI0VROhWBrQhc11BNVdPlmkF4SDCPXDDGXs5j8BjD24u3898F27hgfC+iw0P41+xN9IiL4JyxGUwakMQR/RLV96ooSocT2E3TFsQIWkJwkPDAuaNYfudP+MWU/sycv41/zd7EWWPS6ZccxeNfr+fCZ37g8a837HduVxvgpyhK1yfALYKDjxE0h7CQIG7+yWCSosPxGMMVk/siIhSVV3HLG0t55PO1DEyJZuXOQlbtLGT97mK25pfy2xMH8/Nj+vtFJkVRlPoEuCJofYzgQIgIl0+uG3CLiQjlnrNGMH/zXq5+aSFBAn2SohiQHE1iVBgPfLKGcb0TyOqTWOe8H7fu5b0lO7j1pCE6fkFRlDYjwBVBw+MI2oPEqDD+dWkWi7fu5ZSRPUiJsf1+i8qrOO0fs7n+1R/58IajiI8MA+D79Xu48sUFlFbW0C85mkuO6N3U5RVFUZqN32IEItJLRL4SkZUiskJEbmigzMUislRElonI9yIyyl/yNEitIvCfRdAUo3vFM2NS31olANZa+MeFY8gtruC3ry/FGMO6nCKu+PcCMhK6MaxnLE99s4FPV+zi/KfmcPu7y1mbs3+6XEVRlObiz2BxNfAbY8xQ4AjglyJSv2P9JuAYY8wI4C7gaT/Ksz9+Cha3lpEZ8fzu5MP4fFUOv/zPIq55eSFR4cG8dMUEfn38ILL3lnH1SwvZll/K6wuymf7sPIorOkaZKYrS9fGba8gYsxPY6awXicgqIB1Y6VPme59TfgBaNhyutQR3rEXQFJdP6kN+SQUvfr+FkspqXr5iAqmxESQPCefI/t2JjQjloZ+OYm1OEWc/8T0Pf7aWP56mA9gURWk57RIjEJE+wBhgbhPFrgAanGpIRK4GrgbIzMxsO8HacBxBWyMi3PyTIfxy6gB2F1bQJykKgKAg4T9XHVFbbkxmAhcdnsnz320ivlso54zLICRY6ribFEVRmsLvikBEooE3gRuNMYWNlJmKVQSTGzpujHkax22UlZXVdh3tOzhG0Bwiw0Lok9T013TryUPIK67koc/W8tBnawG468zh/DQrgzcWZjO+TyKDUmPqnFNQWkVstxAd0KYoin8VgYiEYpXAK8aYtxopMxL4F3CyMSbPn/LsRyeNEbSU2IhQnrxkHAu35LN6VxEfL9/Fn95bwatzt7Jyp9W9Z49N56HzRiEifLd+D5c9P5/pE3tz22lD8XgMQZogT1ECFr8pArFNzWeBVcaYvzVSJhN4C7jEGLPWX7I0ShewCFqCTZ+dyGkjezLtsdls2lPCQ+eNYvG2fbz0wxbOHZdBbEQoP39pIQg8+90mukeH8+zsjVw+uS+/mDKgox9BUZQOwJ8WwSTgEmCZiCx29v0ByAQwxjwJ3A50Bx53XBTVjc2p6Rc6cByBP4nrFsrbv5hEWVUNPeO7cerIHny6chf3friKXQUVxEaE8NKVE5j+7Dzu/3g1wUHC419t4KLDM2vHLSiKEjj4s9fQbKBJf4Mx5krgSn/JcEAOMYvAl4SoMBKc9YjQYH4xZQB3vLeC+MhQZl49kf7J0Tzxs7F8uiKHYw9L4ezHv+fxrzdw7JAUhqTFqEJQlAAisEcW16ah7toxguZw/vhebM4r4czR6QxIsYHjkRnxjMyIB+Dk4Wk8PWsjT8/ayOQBSbx0xeH7BZKrazzMWpfLlEEpGlNQlEOIwFYEfk4615mICA3mjtOHNXr89tOHMqpXPLsLK3juu018vmo3ldUeoiNCaqfgfP67zdzz4SqemZ7FCUNT21F6RVH8SYArgs47jqC96RHXjWuO6U9VjYev1+zm5y8twON01B2bGc+fzhjOP79eD8DnK3NUESjKIYQqAggIi6C5hAYHcfeZw7nv49VcMbkvpZU13P/xak5/bDYAQ3vE8sXq3Xg8BhF0HIKiHAIEuCIInBhBSzhyQBLv/co7tm/ygCRuem0xg9NiyOqdyI3/XcyjX67j5R+2cMtJQzhtZA8+WraLk4anERUe2D8pRemKBPa/NigIELUIDkCvxEhev+ZIAPaVVhIcJDzy+TrCQoK45Y2l/PWTNeQWVbByZ6HmO1KULkhgT1UJ1j10iI0j8CfxkWFMHZxMv6QovvrtFE4alkZKTDhHD0rmpR+2sGTbPv78/kqe/GYDW/NKAaiq8bB9XxkA5VU1rNrZYKYRRVE6COlqc+RmZWWZBQsWtN0F706Dw6+EE+9uu2se4pRX1RASJIQEe9sR2/eVMfWvX1NZ4yEkSKj2GCLDgnnvV5O5/+PVfLV6Ny9efjj/mr2JL1fv5rZTD+PKo/p14FMoSmAhIgsbG7Ab2K4hsGMJNEbQIhqaJjM9vhvXHTuAr9fmct/ZIwgJDuKcJ77n3Ce/Z19pFTERIVzy3DxqPIYhaTHc/cEqVu0s4rysDArKqhiZEUePuG51rrk2p4h9pVVk9U7QcQuK4kdUEQQFa4ygjbjuuIFcd9zA2u2HzhvFZS/M59ghKdx+2lB++tQcTh6exh9PG8p9H63m5blbeHNRNmCn7nzqknFsyStlX2kluUUVPPPtRjwGeiV247xxvThlRA/6JUXhdlQSEfKKK1i8bR/FFdV8ujKHwrIqnpsxnlDHWskpLGflzkKqawzHDdl/IFxFdQ3VNdZ60R5QSqCirqG/DoAhp8Hpj7TdNZVaVu4opF9yFBGhwVTXeOq4k/aWVLJgy166hQZzyxtL2FFQXufcs8emc9TAJN5YmM13621i2ojQIKprDFHhIYzMiGPepnwqqj0ARIeHUFxRzd8vGM34Ponc88EqPlq+s3Y8xDGDknn4/NEkRtn0Ge8v2cFvXl9CZbWHqYOTefbS8XUUxfzN+ezYV8a00en+fEWK0i405RpSRfDQEBhwPEx7rO2uqbSY7fvK+M/cLRw7JIX+ydGUVNaQHu91FW3LL2XOhjzW5BQRFhJEblEFi7bsZUK/RM4em0FMRAh9k6I4+e/fEhESTFAQbMwtYfrEPhx/WAqrdhZy1/9WERcZym2nHgbAza8vZVh6LMN6xvLyD1u596wRrM0pIntvGUcNTOKeD1ZRWePhv1cfwYR+3dv8mfeWVHLHeyu4bFIfxmTazFDGGCqqPQ263xSlNagiaIqHR0CfyXDWE213TaXD+M/crfzh7WUA+6XCWLGjgN+8toTVu4oA6JcUxZvXHklct1B++tQcFmzZC0BMeAhFFdWMSI9jX1klgpASE05OUTm3nzaME4amsmTbPm5/dzm7CstJi+vG3dOGszmvhI+W7+T4w1LJ6p3IjoIy/jN3K8N6xvLzY/rzh7eXsSWvhJtOGMy43gn8/q2lvDpvGwmRobzhyPGLlxexPreY135+RG1OqLakusbD099u5PA+iWT1SWzz6yudF1UETfH30ZAxHs55pu2uqXQY5VU1THvsO34yPI2bThi03/HKag/zN+cTHCQMT48j2hkAtzaniF/9ZxE/P7o/Jw5L5dMVORw/NJUVOwq46Jm5pMVGENctlDU5RcR1C6W4otp2mx2YzKx1ueQUluMxXveUS3CQUOMxXD6pL899t4mI0CDKqzwcPSiZb9flcsaonny3fg97iisJCwlCgKjwECJCgnjj2iPpGd+N8qoawkOCmhXDyCuuoHt0OAAlFdX7xT4e/WIdf3NmsZs6OJkzRvfk5OE9ai0QYwxb8krxGEOQCFHhISTHhLM2p4jPVuZwxeS+tWW/WrObiqoafjIsTeMrXQBVBE3xjyxIGw7nvdB211Q6FGNMm1ZM63cXk5HQjSARZs7fyrqcYiLDbWrvuG6h7C2p5N4PV9E/JZorJvdlwea9bN9XRkRoEBP7dee8J+ewcU8JI9LjeOWqCbzw3Wae+mYDsd1C+eymY8gtquC9xTvIL6ngvKxeiMAFT/1AalwENx4/kN+9uYzTRvbgnrNG8NdP1gAwPD2WZdsLKKusITU2glNH9ODFOVt47rtNnDm6J93CQnh13la6R4VxzKBkLj4ik50F5dwwczEnDU9jSGoML8/dQk5hBaN7xfPM9CzCQ4O44dUf+WpNbp3nH5waw4bcYqo9ht+fPIRLJvbm928t493FOwAY1SueYwYlMyAlmkGp0QxOjanz/t2staMy4muVVH1KKqqZ8fw8eiVE8sC5I+vEkmav20N+aSWnjehxwN5jecUVxESEEhbiPd/jMbw6fyvJ0eGcMDR1v99GeVUNs9bmMnVISm0nA4/H4DGG4CDhgU/W8P6SHaTEhHPdsQOZOiRlv/saYyirqiEyzNv/psrpSt1Wv8Vt+aWkx3c76B50qgia4p9HQNIAOP/ltrumoviwNHsfd7y3gvvOHsngNOvu2VdaSY3HNFoxztmQx6XPz6Oy2kNsRAiF5dWMyYznx637aq2M0GAhMiyEgjLvgMijByXz/fo9eIzhwsMzKauq4dMVObVWSkZCNz647ijiIkPxeAwfLt/Jb19fgjEQJEJVjYcbjx9Ir8RIPMaQU1jBV6t30y85ii15pazYUcioXvHMXpfL9ccNpGdcN56atYFNe0rqBOWzeifw7HebSIoOp6K6hm35ZaTFRnD3mcMJDhKWZO9jV0E5U535L+7/eDUfLd+FMXDqyB6cODSVIWmxFJVXcdEzc6ms8TAoNZoBKdEUlFWxY185xw5JYULfRJZtLyAtLoJ1OcX8e85mkqPDOWtMOskx4USHh/DZyhy+WL0bsLmy7jtnRG369fySSq5+cQELtuzl/Kxe3HfOCL5ek8sd762goKyK8X0S+HzVbiYPSGLHvjI255Vww3GD6J8SxQdLd7I5r5SLJmTyyfJdzNuUzy+nDiAmIoQPl+1kSfY+RqTHce/ZI3hxzhZW7ywkLCSInnHd6JUYSUJkKD9szGdzXgkiwqiMOKYMTubwvt1Zmr2PwvJqfjIslfCQYLbklXD2499z5pj0gx69r4qgKZ6cDHG94MJX2+6aitIGfLV6N5+u3MWtJw3h6pcWMm9TPtcfO4Arj+7HxtwShqTFEBEazM6CMmbO20ZGQjfOy+rFhtxiPB7DwFSrdArLq/hy1W5SYsIZ1St+v3xQy7cX8Nai7VR7PEwb3ZNxvRuOHazcUcip//gWY+Ces4Zz8YTetcfKq2rYnFfCrLW5PPzZOsqqapgyOBljbBfdM0al8/jX68nea0eYi0BUWF032v+dchjlVTU89Jl31lpbcUbwi6kDeHXeVorLq4kMDyG+Wyiz1++hxuOtv0TggvGZZO8tZfb6PbhVW0iQcNuphxETEcoDn6xmT3El43onUFntqZ3T+9jBKXy8YhepseHkFFbQPzmK9IRIZq3N5WdHZHLXtOGUVtbwq/8sqrWY4iNDSYuNYPWuIqLDQxjbO4FZa+2xYT1jGdc7gdcXZFPmDMAc3yeRao+H7XvL2FlYjjGQFhvBiIw4qmo8LNy8l6KKul3Ze8ZFcNqonny6YhcFZVW8ce2R9E+Obv6PyAdVBE3x9BSISoaLX2+7aypKG7OvtJKFW/Zy7JCUDvXHP/XNBsJCgrhsUt9Gy2TvLWV3UQVjMxPq7C8oq2LRlr3ERIQwMDWGyLBg5m3KZ1dBOQlRoUwdbJ9td1E5hWXVfLV6N7PW5XLnGcMarPyy95ayY185I9Lj2FNcgTGQ2T0SgBqPobSymuKKasJDgmu7DBeUVvHQZ2tYvauIILGTM00b3ZOhPWK5/d0VbNxTzLRR6Zw5Jp2wkCC27yujZ1xE7Ts3xrCjoJz84koGpEQTERrE/M176d09ktTYCH7cupduYcEMSYsFbAeFl3/YymWT+jAo1Rv8r6iuIb+kkrRY77Wrajz8uHUf8zfnMzg1hpBg4V/fbmLepnyCguCVK49gXO+677QlqCJoin8dD2HRMP2dtrumoihKG1FeVUNJRXWjbsTmoikmmiIoREcWK4rSaYkIDfb7uBLNPhoUormGFEUJaFQRqEWgKEqAo4pA5yNQFCXAUUWgFoGiKAGOKoJgjREoihLYqCJQi0BRlABHFUFQCNRojEBRlMBFFYF2H1UUJcBRRaCuIUVRAhy/KQIR6SUiX4nIShFZISI3NFBmiIjMEZEKEfmtv2RpElUEiqIEOP5MMVEN/MYYs0hEYoCFIvKZMWalT5l84HrgTD/K0TQ6jkBRlADHbxaBMWanMWaRs14ErALS65XZbYyZD3RcTawxAkVRApx2iRGISB9gDDD3IM+/WkQWiMiC3NzcA5/QEoLVNaQoSmDjd0UgItHAm8CNxpjCg7mGMeZpY0yWMSYrOTm5bQXUGIGiKAGOXxWBiIRilcArxpi3/Hmvg0bHESiKEuD4s9eQAM8Cq4wxf/PXfVpNUChgwOPpaEkURVE6BH/2GpoEXAIsE5HFzr4/AJkAxpgnRSQNWADEAh4RuREYerAupIMiyJnwwVMNQWHtdltFUZTOgt8UgTFmNtDk5KrGmF1Ahr9kaBZBzivwVAOqCBRFCTx0ZHGtItA4gaIogYkqguBQu9SxBIqiBCiqCHxjBIqiKAGIKoI6MQJFUZTAQxWBqwh0LIGiKAGKKoIgN0agFoGiKIGJKoLaGIEGixVFCUxUEWiMQFGUAKdZikBEokQkyFkfJCJnOHmEuj46jkBRlACnuRbBLCBCRNKBT7GpI17wl1DtSrDGCBRFCWyaqwjEGFMKnA08bow5DxjmP7HakfoxgurKjpNFURSlA2i2IhCRicDFwAfOvmD/iNTOuK6hwu3wzi/h7hTYNKtuGU8NfPx7+PYh2Le1/WVUFEXxI81NOncj8HvgbWPMChHpB3zlN6naE1cRvPVzwNhP9nzoe7S3zMp34IfH7frsR+D6HyEqqX3lVBRF8RPNsgiMMd8YY84wxtzvBI33GGOu97Ns7YM7jiA4FC7/GKLTIG+j97jHA7MehKTBcNWXUFEIc5+C7Yvgq3u126miKF2e5vYa+o+IxIpIFLAcWCkiN/tXtHYisR+kj4MLZ9plYj/I91EEaz6E3Svh6N/a40NOg3lPwctnwzf3w7pPO052RVGUNqC5MQJ3spgzgY+AvtieQ12f6GTb0u97lN3uXk8RrHofolJg2Nl2e/JNUF4AEmStB9dl5Etlif/lVhRFaSOaqwhCnXEDZwLvGWOqsA71Q4/EflC8CyqK7XbOCugxEoKdWELGOJj2OFz6PzjiWhtY3r7Ie/7Gb+D+PrB3c3tLriiKclA0VxE8BWwGooBZItIbaL/pJNuTxH52uXeTTUS3Zw2k1uspO+ZiSB0K4y6F0Ch4Zir8I8sqj21zoaYStsxp2X3zN8FadTMpitL+NDdY/KgxJt0Yc4qxbAGm+lm2jiGxv13mbbCfmkpIaWTIRLcEuOoLmHAN5K2DnYshd7U9tn1hy+77zf3w+gwwh6ahpShK56W5weI4EfmbiCxwPg9hrYNDj8S+dpm/EXavsOupQxsvn3KYjRsA7FoGuWvs+o5FjZ/TEDuXQlUJVBa37DxFUZRW0lzX0HNAEfBT51MIPO8voTqU8BgbHM7fCDkrQYIhaVDT58Sk2nN2LIY962wgedeyxkcp79sKT0+1ZQCqyq0LCqB4d5s9iqIoSnNoriLob4y5wxiz0fn8CejnT8E6FLcL6e6VkDQQQsIPfE7aCFj7MdRUQP/jrEspZ7k9tup9WPGOXTcGPviNtRi2/mD35a725joqzmnzx1EURWmK5o4sLhORycaY2QAiMgko859YHUzaCFj4PIR0g4EnNP+cDV/Y9dEXwfrPbJwgewF85Ay52PUbCInwjj1wK33XMvDddyBK8mD23+D4O72J8xRFUQ6C5iqCa4AXRSTO2d4LXOofkToBx/0Rdi21PYCaig/4kjbCuz7gOIhKhg9vBgwMPtW6nL59yB7PnAh56+sqAgkGUwPFuc273/rPYc5jdnxDxrhmP5qiKEp9mqUIjDFLgFEiEutsF4rIjcBSP8rWcUTEwSVvw5zHYWwz9V3aSLuM6WnPP+522PEj9BwLoy6wFX3W5RDZ3Qakn54CRT6KIH2sHY/QXIugwum9W6IxBUVRWkdzLQLAKgCfzZuAR9pUms5EWBQc04IsGt37Q2gkJA+222On248vmRO869GpduCax2MVwajzoSC7+YqgfJ9danBZUZRW0iJFUA9pMykOBYKCYeofvOMQDkRMqlUAhdlQWWQHrW2b1/yKvVwtAkVR2obWKAId+VSfI69rftnoNFuJ566120mDHCuhuRZBgV2W7LE9kfLW2x5OiqIoLaTJ7qMiUiQihQ18ioCe7STjoUlMGhgPbHO6kHYf4CiCZrbw3RhB8W7Y8h08lgVrP/GPrIqiHNI0qQiMMTHGmNgGPjHGmCatCRHpJSJfichKEVkhIjc0UEZE5FERWS8iS0VkbGsfqMsQnWKXm7+DsGirBKJToCTXxg0ORK1FkAu7V9n1OY/5R1ZFUQ5pmjug7GCoBn5jjBkKHAH8UkTq98U8GRjofK4GnvCjPJ2L6DS73L7AWgMiVhl4qryB4KYo97EI9m2x65tmwa7lfhFXUZRDF78pAmPMTmPMIme9CFgFpNcrNg140Ulk9wMQLyI9/CVTpyIm1S5rKq0iAK+V0Jw4gW/30b1bbLfVkG4wN3B0qaIobYM/LYJaRKQPMAaYW+9QOrDNZzub/ZUFInK1m/AuN7eZA646O9Gp3vVaReDsa44icF1DZXttltTUoTDmZ7Dkv7BvW9PnKoqi+OB3RSAi0cCbwI31xiE0G2PM08aYLGNMVnJyctsK2FGEdoNwZ6D2fhZBMwLG5YU2tgCQuwoS+sAkJwzz3SNtKamiKIc4flUEzqxmbwKvGGPeaqDIdqCXz3aGsy8wcN1D3Z2xB65FUHCAFn11JVSXec8zHojvDfG9bJ6jRS9C4U7/yKwoyiGH3xSBiAjwLLDKGPO3Roq9B0x3eg8dARQYYwKnBnMrftciiIi1k+Cs/7Lp89z4gHseWIsA4Ihf2LjDOu1KqihK8/CnRTAJO8H9sSKy2PmcIiLXiMg1TpkPgY3AeuAZ4Bd+lKfzEZ8JselWAbgMORW2fm8HigH8+DI8MclOm+nixgfqKILedpk8GLolwrb5B77/ljnw/o3N666qKMohS2tGFjeJk7K6yTQUxhgD/NJfMnR6jv2jbcH7cthpMOsBO7dBxuHwwW+tG6hwh7eyr1UEPiOJXYtABHpNsJlTD8S6T2267cNOtxlTFUUJSNql15DSCLE9IG143X1pIyEuE+Y+Bf+92CoBqBtAdl1DsT1sl9GIeJvx1KXXeDuHcml+0/evrrDLBc+16jEURenaqCLobIjA0DPsfAhV5XbiGbCZSiuKYOW7XosgIg6ik73WgEsvJ8tp9gHcQ9XldrnmQ5v5VFGUgEQVQWdkyu/hqi/hhiUw6iK7r2gXLJkJr023s54BhMdCv6kw4Pi65/ccY+c/OJB7qKbCps42Hlj2ets/h6IoXQK/xQiUVhAeDenOrGNRSSBBdpBZleMm2jzbLiNi4YxH9z8/LMrOmLb6Axh/lXUhNUR1hU1+V7JH5zVQlABGLYLOTlAwRKVYi2DfVrtv5xK7DI9t/LzJv7apJx6fAJu+bbhMdbmdQzk0EiqL21ZuRVG6DKoIugIxzjwFriIwNRAWY5VEYww7E66ZbZPbvXoBbF+4f5nqCggJtxZEZalfRFcUpfOjiqArEJ1a1yKAur2EGiNpAEx/186T/J8L9u9F5FoEYZFQWdK2MiuK0mVQRdAViE6FvZuhLN+bvjqiCbeQL7E94IJX7Lkf/77usepKCA6zOYuqVBEoSqCiiqArEJPmHTsw+GS7bCo+UJ+0ETD5Jlg6s268oE6MQBWBogQqqgi6Ar4pq4ecapfNcQ35MvlGu3SnxgSfGEGkxggUJYDR7qNdgZg073qPUTbHUGNdQhsjLMrGCgp8kru6FkFQsFoEihLAqCLoCrgWQUgERCXDpe9bd05LiU2vO4LYtQiCwzRGoCgBjCqCroCrCOIzbQqK2J4Hd524DBt0dqkut4pAYwSKEtBojKAr4KsIWkNcRl3XUE2l0300yioFT03rrq8oSpdEFUFXIDQCYnpA0qDWXSc2HSoK7DSX4LUIwqLstloFihKQqGuoq3DZhzbY2xriMuyycLt1B3mqvd1HAapKmz8+QVGUQwa1CLoKif1a3mW0Pq4iKMi2mUfBsQii7bpaBIoSkKgiCCR8FYE7KU2wM44AVBEoSoCiiiCQiE6zKa0Lt3snpfGNEVTpoDJFCURUEQQSwSE26OxrEYREQKgbLNZU1IoSiKgiCDTiMuopAt9eQ2oRKEogooog0HBHF9e6hiI0RqAoAY4qgkAjpoedlrLWIgjz9hrSNBOKEpCoIgg0ImJthe9W+r7jCNQiUJSARBVBoBEeY5cleXZZRxFojEBRAhFVBIGGO6FNSa5dhoRDUJBOYK8oAYwqgkDDTSFRstsuQyLsMjRSxxEoSoCiiiDQqHUNORZBcJhdhkUdWq6h8sK603IqitIoflMEIvKciOwWkeWNHE8QkbdFZKmIzBOR4f6SRfEh3MlXVOy6hhyLICzq0HIN/fgyvHgGlO3taEkUpdPjT4vgBeCkJo7/AVhsjBkJTAf+7kdZFJf6FkFIuF2GRR1arqHSPWA8ULizoyVRlE6P3xSBMWYWkN9EkaHAl07Z1UAfEUltorzSFtTGCPbYpW+M4FDqPurOuVC8a/9jxrSvLIrSyenIGMES4GwAETkc6A1kdKA8gUGtReAGi12LIPrQihFUFNllUT1FsG0+3NMDinLaXyZF6aR0pCK4D4gXkcXAdcCPQINzJYrI1SKyQEQW5ObmtqOIhyChkSDBNsVEcJidAxlsmolDKUZQ4VgE9RVB7mqoLrNpNhRFATpwhjJjTCFwGYCICLAJ2NhI2aeBpwGysrLUrm8NItYqKN/ndQvBoRcjqHUN1Wv5uwpC02koSi0dZhGISLyIOH0XuRKY5SgHxd+4cQLXLQQ2FfWhFCOoKLDL+hZBubP/UHKDKUor8ZtFICKvAlOAJBHJBu4AQgGMMU8ChwH/FhEDrACu8JcsSj3c0cX1LYLKEhtIdd1FXZnGLAJ3/6HkBlOUVuI3RWCMufAAx+cAg/x1f6UJwhuwCMIiAQNVZd601F2Z2mBxve6jrkVwKLnBFKWV6MjiQCSiAYvAVQ4Vh4B3zhifYHFO3e6i7n51DSlKLaoIAhG3C6mbXgIgwhlx7LaYuzJVZeCphsjutofQrqXw0e/AU+MTI1DXkKK4qCIIRBqKEXSLt8uyfe0tTdvjtvqTBtvl53fC3Ccgf6O6hhSlAVQRBCKuReAbI4iIt8vyfe0tTdvjBoSTBtrlhi/tsiRXXUOK0gCqCAKRhmIEtYrgEHANuYHipHp9EUpyfSyCQ6irrKK0ElUEgUhDvYa6qmuosnT/xHLuGIIGFYFrEagiUBQXVQSBSEOKoKsGi2c9AM8cW3efW9nH9rQD5XpPstt7t4Bxspioa0hRalFFEIg0FCMIDrWVZleLEexeDUU76lbsbhwgIhZOfRBOvBu6JdhgsYu6hhSlFlUEgUhDMQKwVkFrFUF1Bfz7dMhe0LrrNEXuWtj4tV0v2GaXvummXYsgPBZGXwTpYyEqGfLWe8uoa0hRalFFEIg0ZBGAjRMcKEZwoBm/9m2DTbNgzUcHK92B+eJP8Pplzv222qVvWmk3WOw+J1hFkL/JroceYtNyKkorUUUQiDQ0jgBsz6GmYgTbF8ED/WDXssbLlDoT3uxZ2/DxkjxY8XazRW2QnOVQlg95G7xuIF+LoKLQzq8QFOzdF9kdairsemwPdQ0pig+qCAIRNzAcHL7//qZcQ7lr7PSP2+Y2XqY0zy73rGv4+PePwuszoLSpyeuaoLwQ9m626+u/8O73tQjKC73KziUq2bse00MtAkXxQRVBIBIRB0NOg94T6+7vFg9lBVCwHb68G2qq6x53E7jtWt74td0pMPM32JQO9dn8rXOtXXZymM//1HC5+sx/Fj67A3av9O7b4KMI6lgEBd44iMt+ikAtAkVxUUUQiAQFwwWvQJ/JdfdHxFnX0PI3YNZfYfvCusfdlM45Kxq/tmsR1FTCvi11j5UXwo7F3mutfA9m/61u5d4Yy9+EOY95FQliYxFgZ107oEWQ5F2P7WFzEHk8B76vogQAqggULxHxtjXt+ve3/VD3uGsR5KxovBJ1FQHs7x7aOsfbj794t+322VC5hijcbhPJ/fCEVVipw22+oJBukDyknkVQ1LhFEBxm4wWg+Ybagqpy+PKerjcQUamDKgLFixs72P6jXW6trwicyraqBPZtbvgaJXsg3LlO/YDxpll2vmSwFoE7Iti3W6cvn/8JPvk/m0a60FEapXlWCSQ7o4bje1lXT1G9YLFvjyHwKoLwWGtBgLqH2oJ1n9hBfcteb/21Fr8Km2e3/jpKi1FFoHhx00zkrrLLrT9Y/70bEyjaBd0H2PXG4gSledC9H0Qm2TJf3Wv7/YP9k2ceYVvxxTleC2PPOps6eunrdS2NtZ/A6v/Za9ZUQphTuacO96aPiOsFMal1FUFTrqGIODsbG2jPobZg83d26Y7rOFgKsuHdX8IXd7VaJKXlqCJQvLiJ54wHEvvbLppvXAZPToKclbay7TcVkMbjBKV7rOslaRAsnQnf3A+LX7YuhF1LIXMiRKdY15Dbys9bD4tfgbeuhPWfe69VtMOOS9jrxBrG/Mwu00Z4FUF8L4hOs7JWV8KGr+y6q9RcXIsgItarCLTnUOvZ4iiCTd/u37mgJfzwhHUbbl8AFQE8V0R5Ifx1AKz5uF1vq4pA8eK6hgDGXGyXK9+1y41f2X74if2ge3/blx+gpqpuK740z1oDKUPsdmikbfHnb7AKJuUwiE61Pv0iH9fQxm/sujvGoKrMDl4zNd5YxYjz4ML/wsif+iiCTGsRAMx+GF46ExL6wthL6z1bvHVLRcTZAWXgdQ2t/wLWfY7SQkrzbYMgdbiNLW34Et6+Bt68CpbMbP51ygtg4b8hoY+NA2353m8id3p2LbPJEXf82K63VUWgePFtRQ86ybaiE/rYgWduSz0mFVKGenv6fHgz/H2UN+BbkmctgqNvhunvwYDjbKwgd409njTIWgS5a6G6HOJ7W5/+us/s8dUf2DQVrrUAXr9xXDoMPsmOiE4eAuMugyGnW8UCtqdTehZc861VVr4EBVn3UHisd05m1zX0+R3w2e2tfXuBx5bvAQPH3Gq3X5tue3dt+ALev9E2EprDirehsgjOfMKObdn0zcHLlL2wa8d+3P9V0Y6my7UxqggUL74WQWI/uOg1mP6ubcW7vuCYHnY7f5NttW+aBQVb4bmTbOVeVQJR3W3mz37H2Io/f5NjQYidLMa1CAD6Hm2X1WW2xe+2LH0VwZbvICik7liA4BA4/REbNHYVgafKKqDQbg0/31G/hbHT67qGaqqt3Pkb685trByYLd/ZRsKgn1h3XXUZnPEYnPqQd4rQHT/C/H81fZ2tc60VmTkReh1+8IqgogieOxG+fejgzu8MuC7X+qnV/YwqAsWLGyOI62Ur0/Sx1iJIHe5NzxCTZlvjGNi5xFagw8+1sYH5z9gybvdMsIrA1NjAb3ymva5bcQP0Pca7fuwfrQwr3/W6jcC6DmJ61E0Z4UtMml0mD4GBJzb+fBOuhoEneF1DVaWwd5N9tuqyuvdsT77/B/z3Z/659oq34Ycn/XPtrXMgY7y10I67A057GEadD72OcI7PhS/+DB/8xsZ6GiN7vlUAIrbxsGuZtSxL8+Gtnx84v5VLQbZ1La39tGXPUbAdXjoLinMPXNaY/RsMsx/xjo9pLbUWwa6my7UxqggUL2FR1o9e362SOty7Hp1mLQKA5W8BBoadZS0IN9FcpM/gLdeXn7Mckp05hKNTvMczsmyrsvtASOht5w7YvtBrEcT3tsvY9Mbljk6F/sfCCX+2LqADPqfbfbS47mA23zTV/qI0H148s27FuOZj+2nOCOuWMv9ZG7Bva2unqsxW2Bnj7fbAEyDrcrse28Mq/TUfemM/y9+0Lfb6vu/SfMhbZ38HAD3H2OWetdbaXDqz6Yq9sgRenAbb5llFAJCzrGUt6pXvWiu0/riZhpj1IPzzcO/73LnUuhYPZPU0B2Ngt9Njz3UNLXujXZSCKgLFi4i1AHqMrrs/zVEE4XG2Ek3sb101bmA3dRhkHO5NCV3HIhjos+4oBV9FEJtuFcnY6d575a23n/BY63IA62pqjKBguORt66JoDr6uIfePBzaJnb/ZscgG3n27W+autm4ttyJrSwq3215UxTkHLtsSdi61rW+3Aq9P5kQ7CtzUQFSKrdBmXgzPnmiViIubrjzjcLuMcb7noh1eCy17fuNyrP3Yvst1n3p/f1A3/ciBcGNQbg6rxqipgnlPOzGv1Xbfjy/ZpRsDaw0F2TZeFtPDdroo3AFvXgE/PN76ax8AVQRKXa78HKb8vu6+1GF26bpgQsLseIKS3TbLZ3xva9q7+KZzCI/x/rlrLQLHNRSZZK911pMw6XrnXsNt76INX9rKP7Gv3d+UImgpvq6h3aus/MFhtmeTv3Fbqu69SvZ4M7bu3dS8a1SV2+B9Y6381R/Cqvft8YLtdp/by6slbPwGHj/Sm9bbF7dyTm9EEfSaYJfxvWHyr20rfdM3djxIvs9zZs+zVmj6WLsd28MuC3d6rcKmFMHyt+wyb4OtSCXYWq1u54MD4amBLa4iqJcSxeOBhS94n3/dp/Y3D1Z5VJXB0v/a7dzVB7a6inPhlfPsO/3qL/sfd63TAcfZpdtYaCq3VxuhikCpS2QihNZLT90tAWIzvN00wYkTYHsQBQXVVQS+FgF4rYKkeq4h90/vi2t9FG63LaPEfk7ZJlxDLSU4xFb8lcVWEaQOt5aQ6xoqzbd/2LZo5dWntsusowh875HfTEXw7YPw8jmw4NmGj392u037ULLHG9tpqDIxxva08rWK6tznIdi9ws4CV5/s+RCXWfc34Uumk9Bw6DQYfra1IFMd6y5vnY0vvXapdRmlDvNaaRHxTu6onT4pTZY3POajoshb4eett4ogNh0GHm+tLk+NbeXPfrjxSjpnuTf1en2LYNsP8P4NsMhp9f/4sm3ExPS0imDlu/bcodNsS963g4NL8W4ngWOVDa6v+9TK2VAqdjdQ3N+ZenXDl3bZVNr3NkIVgdI8Tr4fjr7Fu+3GCdyKO2WotQ4k2Bt0dnFdQm5aiChHEcQ00MqP7+MdQRzb00cRtKFFALayKdtrK5CUw+x98hxFMPth+4dd9kbb3hO8lYVb6e/xVQTNiFHUVMOPr9j1T/5vf2Xl+tzzN9reXC4NDQAsybWV1DvX7p87as96b++dvZvqWhdg4ziNuYXAvtNpj8OkG60lec13tgca2He+ZCasfMfK2W+K9zwR2wAo3G6tAgm2LqidS/a/x5qPrKLrMcpeZ982iMuAvlNsBb1rqR2o9vmd9j0V5cC3f6v7rK5bKH3c/kkS3cFyW+dYpbr2Exh1ge3ptnk2fPMAJB8G46+y5dwR+SV7YM7jdoDjp3/0JnAsdN7f4JMa7piwc7FVrm6DybUISnbXTaroB1QRKM3jsNOg71HebdcicN1GQY553y1h/4Bt1mVwwl32GFiLIyrFBofrExTkvWZsTxs8PuGupnsDHQxh0bBtvvVhpxxm4x75G23lM8/p/dScgU2eGttym/NPePdXtpdLdWXj5d0KwO2umrvGytJ9YPNcQxu+sP7zUx+yyqz++AfX515TYXvtgHWVNKQIXFfIjh9txllfFj5vW/FgW8rrPoNHhtuutkW7rD/eDRQ3hIgdlBjlWIcpQ+x6TA+rZHb8aN1Ht2yyPY58ie1pv4eiHdBnkvNcjnuoqtxW8sbAguetpTrqImvd7VpqFYF7zubvvBlqt/1gA7pf/MnrJqsohhXv2EZA5kQ7252vknC//60/WCVgamDY2TZrb+ke6947/k7bCAKv5bTsdfjk9/Dq+V7X0b6t1hIIi7a/t4rCui43j8fK2vcob6OnJNc7Z0iOf62CEL9eXTl06TPZVtIDjvfuO/qWhiuz1GHeyt1l+jt1u5H6kjbc/nFjekBwqDd+0JaERdoWXLcE+yxle20X0jcut37swadaP3x1xf5Tevry/g3egGFopI07HPkrb5C7Pq5FUFViK9Tc1dZiikqG/M0HlnvRi7bs2EttRf7D47YF6sZlsud5y7ot+oEnwJJXrYIKCfMed10h0Wm2m+fwc60iNsa22IecapVl/ib7TozHto5dhd6URdAY3QfYZ85dbTsIRCbuXyamh/3+i3Nh8Cm2El39P+g/1bqTqspsD7Gt38PJD1glDlYZxPeyFWlCX2txuH73rXO9SRD3rLXv8IVT7LOd8le7v7rcBtVje1hXzta51rot2W0ti5ie1vpwx9v0nmw7KIjY67kWgWvZbfjSmfVvn/2uCrZZ15Xr5izcCcmO9btrqf0N9pti329wuFXmg0608Z5dy+v+19oYv1kEIvKciOwWkQYjHSISJyLvi8gSEVkhIpf5SxbFD0QlwWUfWt+6S9+jvL1/DkTqsLpB5TrHHHdTW7uDfInPtFbNVV9a14XbZTZ7Ppx4t23N1lTY6TkbY+nrVglM/BXcvAFm/M/ud1vaxsD/fm1dTS5FO635D7bCyF1j5Ujs1/CgtuoKeHwizH3aun3Wfgwjz7cKctQF1m3iBkzBdqN0XW6bZ9sKpd8UW65+Nlg3g+wxt9hKyq3I9qyzLd4Bx9tg/d5NXoti+0I7Q11IhK0UW0rSQGsNVJV6u4rWJ7aHdfNUl1mlcMQv7PfypNMSL99n81LF9LAKsXs/77lxGXbZZ5LXiojPtJXyDue7zF1j/fv5G21vs8Ov8v6OXffQzqVWWR9xrd3OWWZdOm7PupP/CtP+YbfBfoeuRZC/EdJGwon3wNnP2AbPvs3WtRaX4f1dF+2wCqey1MY0wI6rEfF2zMicaK0eP8cJ/OkaegE4qYnjvwRWGmNGAVOAh0QkrInySqAw8ATrh23K9dBaLvgPXPu9NwbR5yjrorj2e5j4C2+w0/UT16e8AD64yQ6eOv5PVqnF97HH3MpkwbOw4Dn49mFboVdXWnPfnRBoxyKrGJIH2Qq3qsQeB9sSLy+0wdTdK+GHf9qWoacaRpxry6QOswFY1/3gqbEV9eCTbZylstim5XC7A6/+X91n2LvFuujcXiquK8SdirTXEU4QfZPXnbJjkbUK0sc1bSk1RvcBgKPsGlMEMT29ZWJ7woSfw5VfWBfQZR/DmU53ymNusW7GuEwICrX74nrZZW/nHUfEQdYVdiS78Vh3V+5qq4yi06yVAd7xKq4Sd3sSjZvhtYAGnWyXInZwYqKPAko5zJnK1VhF0L2/tQwHnWiv7bqG4jKsAgNrHb53PTyWZb/nlKHe4LurLJKHWOvyYHp9tQC/KQJjzCygqYlpDRAjIgJEO2Vbkb5QOWSIy4BL32/cYmgLQsLrjlQODoWjbvIGtCMT7R/TVQQLnof/XOBtsf/4svXznnyf7YXknhMWbSuTvA02mBvf26bNWPeZN61GRpatuL79m93uPcm6MsBWItvmwbPHwyvn2qBjcJh143x1ry3nO85j5E9txs69m23vn8pi24PLtXBi0yFpAAw9097Pd6zE3s22oo/vbStfX0XQLcFW2gl9rdz7ttpny1lpA7eZRxzce+/u9CALi/amNK+PryXorqePhbOegNShdtzJb9d7B7AFh3hb9L4WAVgF39tZD4+F/k7uqx0/1lVE8Zned1JeaF1wyUNsyzxzonX7uelQGiJlqM2XtGedfVe+SiI+0+4v2V3XIijcYd914Xbb4vcNmvuOlu8xysp8sPN8N4OODBY/BhwG7ACWATcYYxqc9kpErhaRBSKyIDe3GcPAFaUtGHCc7Uu/fZENMq79yPpyPTUw90nIPLJuZSLibf2t/cT6nKe/Y8dLLHvdO4YgrpcNlJflWzdPr8O9FcfaT6wCCYuxlUTOMhssD4+1FfLws73uCFdGsP5sNz6QMd5byboV40n3WeX39FS4N932uNm3xcohAr2PdGaQM/a+GYfbeIE7jgNsBWxqrFXiWkwtJcmRq8eoxlOG+CoCt/Vcn+jkutu+ig9s5TvxV9aa6DHKzoHR92irSPLW24rV97sLjbD32rEI3rrKKoRTnZxFJ94NF/13/27VvrjW6/I37fvxVQQJvb2dBOIybJqVbglW6edvhMNOt7KMPN97TspQJ57Q07qkjGd/i64N6UhF8BNgMdATGA08JiKxDRU0xjxtjMkyxmQlJyc3VERR2p4jb7D921+c5uS7ETvP8ur/2cre9R/7ktDbVrC7llrXQ2I/W3mv/djbVTS2h23pRcRbPzLYimzIaXYO5+x5cNK9MPU26/oZOx2Gn2PLDTur7v2Sh9gBctsXWndSZHcnVbhT4boVY2wP61IZcJy1fn582boqXJdI74m2stqxyFaSmc6AMN8Y0JhLnBU5eLddfG/rrmnKovCt/BtTBPXJGG+f23eK0p/cYyv/kDC48FU48S77vjzVgNnfNZXY335Paz+Gn/zF68Lr3r9pawCsaygsxuumq28RuLiKOaanM07AwIifwtVfQ8/R3nKTf23dlCLWAkzo2/DYgzaiI3sNXQbcZ4wxwHoR2QQMAeY1fZqitBPRyXDUb2wumQHH28Deirds6777QNujpT7xva0VYQz0GGn3jbrApiaY/YjdjukJpzxoA6Zuy1YEfvqSnfYxdzWMvti2mI+52R6f+gfbCvfN+wS2TM8x1j1UXmhb8iI+FoHPQLzDTref966zYxGMx1vRZx5plx86Y0XckcGuyyo8zlou0anWwqk/8U9zCQqGa2bXzSRbn+hUkCDolli3l1NTTP41HHld48fdWIDv3Mr1FcFpD1tffNqIuqlRmkNQMGSM8/b9r6MIfLpJ1yrmnnawHuzfow6ssnbfsYhtAHz397o9xNqQjrQItgLHAYhIKjAYaIesX4rSAiZcY4ONJ94NQ89wBi5tsZVGcAPtqITeNuibu8rbqyZ9nPVV52+wvXgiE20LvaE5E6b8Ds57YX+3SXSKzezp6xZyyRhn/fZ566CX01LvOdoOxkobuX/5QSdbF48rL3iDkjsXW9dVTyflQ2SidUulDrP3PuEuOPa2Zry4JnCz0DZGcIgNYjc08rwxgoKbF7z2neK0vnspeZC13lqqBFzcfEmhkXW7RvtaBL4Wmls2wcf91hjDz7bf2ar3Dk62A+A3i0BEXsX2BkoSkWzgDiAUwBjzJHAX8IKILAMEuNUYs8df8ijKQREaAac5Qd1uifDR76wv13dwnS++rT/f7pVH3WSTsMWkNVyZt4b0cY67A29llDQQfrfF5nqqT78ptvunOzEQWCV0zez9y4pYP7trYYw6f/8y/iBtuHcEelsSHm1dQAfT9fVAuFZUYr+633FcL8AZa+DGGVyFkHJY8zLmpg63jYmGw6itxm+KwBhz4QGO7wDaeLiooviRmFT4xZy6lX19fFt/vq3xflNtJX2wLpWmcBO/+SZvg4aVANjBdH2PdhL7NSOHU2stgIPh/Fese8gfXPKW7bXU1mSMs8vEei38kDDrCvK1EtzYR0NuoYYQ8Y5T8QM6slhRWsKB3AauqyUivq5SELGDl/xBbE8bmI5O8SZvOxBT/2BjHA25tzoDTfXQaS2+AfC2pFuCdSX2PnL/Y0OnWYvSxe0ZldJMReBnOumvQFG6KOEx9g+fNmJ/F1C4H1qhYO9zygMta+X2HNP4gC7l4Dn5/ob3n1Qv7XSP0fY34nb/7WBUEShKW3PCn+paA+3B0Gntez+ldUQnNxyT6SBUEShKW9PcfEuK0knQNNSKoigBjioCRVGUAEcVgaIoSoCjikBRFCXAUUWgKIoS4KgiUBRFCXBUESiKogQ4qggURVECHDH1J8vu5IhILrDlIE9PAjprhtPOKpvK1TI6q1zQeWVTuVrGwcrV2xjT4EQQXU4RtAYRWWCMyepoORqis8qmcrWMzioXdF7ZVK6W4Q+51DWkKIoS4KgiUBRFCXACTRE83dECNEFnlU3lahmdVS7ovLKpXC2jzeUKqBiBoiiKsj+BZhEoiqIo9VBFoCiKEuAEjCIQkZNEZI2IrBeR33WgHL1E5CsRWSkiK0TkBmf/nSKyXUQWO59TOkC2zSKyzLn/Amdfooh8JiLrnGVCB8g12Oe9LBaRQhG5sSPemYg8JyK7RWS5z74G35FYHnV+c0tFZGzjV/aLXH8VkdXOvd8WkXhnfx8RKfN5b0+2s1yNfm8i8nvnfa0RkZ/4S64mZPuvj1ybRWSxs78931ljdYT/fmfGmEP+AwQDG4B+QBiwBBjaQbL0AMY66zHAWmAocCfw2w5+T5uBpHr7HgB+56z/Dri/E3yXu4DeHfHOgKOBscDyA70j4BTgI0CAI4C57SzXiUCIs36/j1x9fMt1wPtq8Htz/gdLgHCgr/OfDW5P2eodfwi4vQPeWWN1hN9+Z4FiERwOrDfGbDTGVAIzgQ6Z5NUYs9MYs8hZLwJWAekdIUszmQb821n/N3Bmx4kCwHHABmPMwY4ubxXGmFlAfr3djb2jacCLxvIDEC8iPdpLLmPMp8aYamfzByDDH/duqVxNMA2YaYypMMZsAtZj/7vtLpuICPBT4FV/3b8xmqgj/PY7CxRFkA5s89nOphNUviLSBxgDzHV2/cox7Z7rCBcMYIBPRWShiFzt7Es1xux01ncBqR0gly8XUPfP2dHvDBp/R53pd3c5ttXo0ldEfhSRb0TkqA6Qp6HvrTO9r6OAHGPMOp997f7O6tURfvudBYoi6HSISDTwJnCjMaYQeALoD4wGdmLN0vZmsjFmLHAy8EsROdr3oLF2aIf1NxaRMOAM4HVnV2d4Z3Xo6HfUECLyf0A18IqzayeQaYwZA9wE/EdEYttRpE73vTXAhdRtcLT7O2ugjqilrX9ngaIItgO9fLYznH0dgoiEYr/gV4wxbwEYY3KMMTXGGA/wDH40iRvDGLPdWe4G3nZkyHHNTGe5u73l8uFkYJExJgc6xztzaOwddfjvTkRmAKcBFzuVB47rJc9ZX4j1xQ9qL5ma+N46/H0BiEgIcDbwX3dfe7+zhuoI/Pg7CxRFMB8YKCJ9nVblBcB7HSGI43t8FlhljPmbz35fn95ZwPL65/pZrigRiXHXsYHG5dj3dKlT7FLg3faUqx51Wmkd/c58aOwdvQdMd3p1HAEU+Jj2fkdETgJuAc4wxpT67E8WkWBnvR8wENjYjnI19r29B1wgIuEi0teRa157yeXD8cBqY0y2u6M931ljdQT+/J21RxS8M3ywkfW1WE3+fx0ox2SsSbcUWOx8TgFeApY5+98DerSzXP2wPTaWACvcdwR0B74A1gGfA4kd9N6igDwgzmdfu78zrCLaCVRhfbFXNPaOsL04/un85pYBWe0s13qs79j9nT3plD3H+Y4XA4uA09tZrka/N+D/nPe1Bji5vb9LZ/8LwDX1yrbnO2usjvDb70xTTCiKogQ4geIaUhRFURpBFYGiKEqAo4pAURQlwFFFoCiKEuCoIlAURQlwVBEoioOI1EjdLKdtlqXWyV7ZUeMcFKVJQjpaAEXpRJQZY0Z3tBCK0t6oRaAoB8DJS/+A2Lka5onIAGd/HxH50kme9oWIZDr7U8Xm/1/ifI50LhUsIs84OeY/FZFuTvnrndzzS0VkZgc9phLAqCJQFC/d6rmGzvc5VmCMGQE8Bjzi7PsH8G9jzEhsQrdHnf2PAt8YY0Zh892vcPYPBP5pjBkG7MOOVgWbW36Mc51r/PNoitI4OrJYURxEpNgYE93A/s3AscaYjU4ysF3GmO4isgebHqHK2b/TGJMkIrlAhjGmwucafYDPjDEDne1bgVBjzN0i8jFQDLwDvGOMKfbzoypKHdQiUJTmYRpZbwkVPus1eGN0p2JzxYwF5jvZLxWl3VBFoCjN43yf5Rxn/XtsJluAi4FvnfUvgGsBRCRYROIau6iIBAG9jDFfAbcCccB+Vomi+BNteSiKl27iTFbu8LExxu1CmiAiS7Gt+gudfdcBz4vIzUAucJmz/wbgaRG5Atvyvxab5bIhgoGXHWUhwKPGmH1t9DyK0iw0RqAoB8CJEWQZY/Z0tCyK4g/UNaQoihLgqEWgKIoS4KhFoCiKEuCoIlAURQlwVBEoiqIEOKoIFEVRAhxVBIqiKAHO/wMqQzYfay342gAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["def create_animated_gifs_acc(model_name):\n","    from PIL import Image\n","    Analytics.create_dirs_if_not_present(model_name)\n","    sort_fn = lambda x: int(os.path.basename(x).split('/')[-1].split('.')[0])\n","    images = [Image.open(image) for image in sorted(glob.glob(f\"/content/outputs/{model_name}/acc_by_class/*.png\"), key=sort_fn)]\n","    images[0].save(f\"/content/outputs/{model_name}/acc_by_class/accuracies.gif\", format=\"GIF\", append_images=images,\n","                    save_all=True, duration=len(images) / 2, loop=0)\n","\n","create_animated_gifs_acc(\"first-model-batch-4clf-1\")\n","print (\"Accuracies by class over the epochs \")\n","from IPython.display import Image\n","Image(open('/content/outputs/first-model-batch-4clf-1/acc_by_class/accuracies.gif','rb').read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322,"output_embedded_package_id":"1L6ip_sWkTjqZ6X_Hj3uESdKYpk8YI91D"},"id":"4AnLFWl02sWT","executionInfo":{"status":"ok","timestamp":1668609795138,"user_tz":-480,"elapsed":4230,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"7bd396fa-5c40-45b2-ee43-c15705eeb4ed"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["print (\"Confusion matrix over the epochs \")\n","from IPython.display import Image\n","Image(open('/content/outputs/first-model-batch-4clf-1/confusion/confusion.gif','rb').read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322,"output_embedded_package_id":"1aN-71hVMm6tu7gugOgK0SHwWaqg_0rPD"},"id":"zUlp1Mp62x8H","executionInfo":{"status":"ok","timestamp":1668609813443,"user_tz":-480,"elapsed":3829,"user":{"displayName":"Sashankh Ck","userId":"01171390207267203018"}},"outputId":"0436b65f-3aa8-44dc-dd04-8543757f5569"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["These results more promising, and show that the embeddings are capturing the meaning better. We also observe that removing the text cleaning actually improves the result - possibly because the word embeddings sum up the meaning better without intervention from the text cleaning approach.\n","\n","We also observe that the model is only focussing on predicting two classes even when not constrained (it can still predict any of the 10 classes). \n","\n","In the next notebook we look at CNN and RNN based approaches. These issues are mitigated there.\n","\n"],"metadata":{"id":"6gp2TqBb3ODu"}},{"cell_type":"code","source":[],"metadata":{"id":"8yVizFNe5f04"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["r7RgadLCm7x2","OugxDX2LnB09"],"toc_visible":true,"authorship_tag":"ABX9TyN7Ft9Q9rNqMariRY5xCGPu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}